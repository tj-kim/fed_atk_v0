{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CW Attack Test\n",
    "\n",
    "TJ Kim <br/>\n",
    "2/2/21\n",
    "\n",
    "#### Objective: \n",
    "Run CW Attack on generic federated learning setting.\n",
    "See what the transfer rate is.\n",
    "\n",
    "The goal is to build an infrastructure of C&W Attack Implementation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/FedAtk\n"
     ]
    }
   ],
   "source": [
    "cd '/home/ubuntu/FedAtk/' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Relevant Libraries and Modules\n",
    "\n",
    "Load the relevant libraries for the federated learning code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import yaml\n",
    "        \n",
    "from femnist_dataloader import Dataloader\n",
    "from cnn_head import CNN_Head\n",
    "from cnn_neck import CNN_Neck\n",
    "from cnn_server import Server\n",
    "from cnn_client import Client\n",
    "from data_manager import DataManager\n",
    "\n",
    "from utilities import freeze_layers\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import csv\n",
    "import os\n",
    "import pickle\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import multiprocessing as mp\n",
    "\n",
    "import queue\n",
    "\n",
    "# Extra not from py file\n",
    "from collections import OrderedDict \n",
    "import itertools\n",
    "\n",
    "# Import C&W Attack Modules\n",
    "import cw_attack.cw as cw\n",
    "\n",
    "# Torch and plotting\n",
    "from __future__ import print_function\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Directly Make victim NN Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Victim_NN(nn.Module):\n",
    "    \"\"\"\n",
    "    Summary: \n",
    "    \n",
    "    Pytorch NN module that takes pre-trained weights from layered personalized model\n",
    "    We also load the data-loader and give test,attack functionality\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, head_network, neck_network, dataloader):\n",
    "        \n",
    "        # Init attributes\n",
    "        super(Victim_NN, self).__init__()\n",
    "        self.head = head_network\n",
    "        self.neck = neck_network\n",
    "        self.dataloader = dataloader\n",
    "        self.criterion = nn.NLLLoss()\n",
    "        \n",
    "        # Image min/max range per channel\n",
    "        mean = [0.5]\n",
    "        std = [0.5]\n",
    "\n",
    "        self.inputs_box = (min((0 - m) / s for m, s in zip(mean, std)),\n",
    "                           max((1 - m) / s for m, s in zip(mean, std)))\n",
    "        \n",
    "        # test_acc attributes\n",
    "        self.orig_test_acc = None\n",
    "        self.adv_test_acc = None\n",
    "        \n",
    "        self.orig_output_sim = None\n",
    "        self.adv_output_sim = None\n",
    "        \n",
    "        # Attack attributes\n",
    "        self.x_orig = None\n",
    "        self.x_adv = None\n",
    "        self.y_orig = None\n",
    "        self.target = None\n",
    "        \n",
    "        self.softmax_orig = None\n",
    "        self.output_orig = None\n",
    "        self.softmax_adv = None\n",
    "        self.output_adv = None\n",
    "        \n",
    "        self.orig_loss = None\n",
    "        self.adv_loss = None\n",
    "        self.orig_acc = None\n",
    "        self.adv_acc = None\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.neck.forward(x)\n",
    "        x = self.head.forward(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    def forward_transfer(self, x_orig, x_adv, y_orig, y_adv,\n",
    "                         true_labels, target, print_info = False):\n",
    "        \"\"\"\n",
    "        Assume that input images are in pytorch tensor format\n",
    "        \"\"\"\n",
    "        \n",
    "        batch_size = y_orig.shape[0]\n",
    "        \n",
    "        # Forward Two Input Types\n",
    "        h_adv = self.forward(x_adv)\n",
    "        h_orig = self.forward(x_orig)\n",
    "        h_adv_category = torch.argmax(h_adv,dim = 1)\n",
    "        h_orig_category = torch.argmax(h_orig,dim = 1)\n",
    "        \n",
    "        # Record Different Parameters\n",
    "        self.orig_test_acc = (h_orig_category == true_labels).float().sum()/batch_size\n",
    "        self.adv_test_acc = (h_adv_category == true_labels).float().sum()/batch_size\n",
    "        \n",
    "        self.orig_output_sim = (h_orig_category == y_orig).float().sum()/batch_size\n",
    "        self.adv_output_sim = (h_adv_category == y_adv).float().sum()/batch_size\n",
    "        \n",
    "        self.orig_target_achieve = (h_orig_category == target).float().sum()/batch_size\n",
    "        self.adv_target_achieve = (h_adv_category == target).float().sum()/batch_size\n",
    "\n",
    "        \n",
    "        # Print Relevant Information\n",
    "        if print_info:\n",
    "            print(\"---- Attack Transfer:\", \"----\\n\")\n",
    "            print(\"         Orig Test Acc:\", self.orig_test_acc.item())\n",
    "            print(\"          Adv Test Acc:\", self.adv_test_acc.item())\n",
    "            print(\"Orig Output Similarity:\", self.orig_output_sim.item())\n",
    "            print(\" Adv Output Similarity:\", self.adv_output_sim.item())\n",
    "            print(\"       Orig Target Hit:\", self.orig_target_achieve.item())\n",
    "            print(\"        Adv Target Hit:\", self.adv_target_achieve.item())\n",
    "            \n",
    "    def specs_from_xadv(self, print_info=False):\n",
    "        \n",
    "        self.softmax_orig = self.forward(self.x_orig)\n",
    "        self.output_orig = torch.argmax(self.softmax_orig,dim=1)\n",
    "        self.softmax_adv = self.forward(self.x_adv)\n",
    "        self.output_adv = torch.argmax(self.softmax_adv,dim=1)\n",
    "        \n",
    "        # Record accuracy and loss\n",
    "        self.orig_loss = self.criterion(self.softmax_orig, self.y_orig).item()\n",
    "        self.adv_loss = self.criterion(self.softmax_adv, self.y_orig).item()\n",
    "        self.orig_acc = (self.output_orig == self.y_orig).float().sum()/batch_size\n",
    "        self.adv_acc = (self.output_adv == self.y_orig).float().sum()/batch_size\n",
    "        \n",
    "        # Add Perturbation Distance (L2 norm) - across each input\n",
    "        # CURRENTLY BROKEN -- need to replace the code below.\n",
    "        # self.norm = torch.norm(torch.sub(self.x_orig, self.x_adv, alpha=1),dim=(2,3))\n",
    "\n",
    "        # Print Relevant Information\n",
    "        if print_info:\n",
    "            print(\"---- FGSM Batch Size:\", batch_size, \"----\\n\")\n",
    "            print(\"Orig Target:\", self.y_orig.tolist())\n",
    "            print(\"Orig Output:\", self.output_orig.tolist())\n",
    "            print(\"ADV Output :\", self.output_adv.tolist(),'\\n')\n",
    "            print(\"Orig Loss  :\", self.orig_loss)\n",
    "            print(\"ADV Loss   :\", self.adv_loss,'\\n')\n",
    "            print(\"Orig Acc   :\", self.orig_acc.item())\n",
    "            print(\"ADV Acc    :\", self.adv_acc.item())\n",
    "            \n",
    "    def CW_attack(self, batch_size = 10, target= -1, confidence=0.0, optimizer_lr=5e-4, \n",
    "                  iteration=1, x_val_mean = (0.5), x_val_std= (0.5), print_info=False):\n",
    "        \n",
    "        self.eval()\n",
    "        \n",
    "        image_data = self.dataloader.load_batch(batch_size)\n",
    "        self.x_orig  = torch.Tensor(image_data['input']).reshape(batch_size,1,28,28).cuda()\n",
    "        self.y_orig = torch.Tensor(image_data['label']).type(torch.LongTensor).cuda()\n",
    "        self.target = target\n",
    "        \n",
    "        if target > -1:\n",
    "            targeted = False\n",
    "            targets = self.y_orig\n",
    "        else:\n",
    "            targeted = True\n",
    "            targets = torch.ones(image_data['input'].size(0), dtype = torch.long).cuda() * target\n",
    "            \n",
    "        \n",
    "        adversary = cw.L2Adversary(targeted=targeted,\n",
    "                           confidence=confidence,\n",
    "                           search_steps=iteration,\n",
    "                           box= self.inputs_box,\n",
    "                           optimizer_lr=optimizer_lr)\n",
    "        \n",
    "        self.x_adv = adversary(self, self.x_orig, targets, to_numpy=False).cuda()\n",
    "        \n",
    "        #assert isinstance(self.x_adv, torch.FloatTensor)\n",
    "        assert self.x_adv.size() == self.x_orig.size()\n",
    "        \n",
    "        self.specs_from_xadv(print_info)\n",
    "        \n",
    "        \n",
    "    def i_fgsm(self, batch_size = 10, target= -1, eps=0.03, alpha=1, \n",
    "               iteration=1, x_val_min=-1, x_val_max=1, print_info=False):\n",
    "        \"\"\"\n",
    "        batch_size - number of images to adversarially perturb\n",
    "        targetted - target class output we desire to alter all inputs into\n",
    "        eps - max amount to add perturbations per pixel per iteration\n",
    "        alpha - gradient scaling (increase minimum perturbation amount below epsilon)\n",
    "        iteration - how many times to perturb\n",
    "        x_val_min/max - NN input valid range to keep perturbations within\n",
    "        \"\"\"\n",
    "        self.eval()\n",
    "        \n",
    "        # Load data to perturb\n",
    "    \n",
    "        image_data = self.dataloader.load_batch(batch_size)\n",
    "        self.x_orig  = torch.Tensor(image_data['input']).reshape(batch_size,1,28,28)\n",
    "        self.y_orig = torch.Tensor(image_data['label']).type(torch.LongTensor).cuda()\n",
    "        self.target = target\n",
    "        \n",
    "        self.x_adv = Variable(self.x_orig, requires_grad=True)\n",
    "        \n",
    "        for i in range(iteration):\n",
    "            \n",
    "            h_adv = self.forward(self.x_adv)\n",
    "            \n",
    "            # Loss function based on target\n",
    "            if target > -1:\n",
    "                target_tensor = torch.LongTensor(self.y_orig.size()).fill_(target)\n",
    "                target_tensor = Variable(cuda(target_tensor, self.cuda), requires_grad=False)\n",
    "                cost = self.criterion(h_adv, target_tensor)\n",
    "            else:\n",
    "                cost = -self.criterion(h_adv, self.y_orig)\n",
    "\n",
    "            self.zero_grad()\n",
    "\n",
    "            if self.x_adv.grad is not None:\n",
    "                self.x_adv.grad.data.fill_(0)\n",
    "            cost.backward()\n",
    "\n",
    "            self.x_adv.grad.sign_()\n",
    "            self.x_adv = self.x_adv - alpha*self.x_adv.grad\n",
    "            self.x_adv = where(self.x_adv > self.x_orig+eps, self.x_orig+eps, self.x_adv)\n",
    "            self.x_adv = where(self.x_adv < self.x_orig-eps, self.x_orig-eps, self.x_adv)\n",
    "            self.x_adv = torch.clamp(self.x_adv, x_val_min, x_val_max)\n",
    "            self.x_adv = Variable(self.x_adv.data, requires_grad=True)\n",
    "\n",
    "        self.specs_from_xadv(print_info)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transfer Attack For Set Configuration\n",
    "\n",
    "As a demo, we will perform a transfer attack from client 0 to the other 7 clients in the system. The implementation is identical to the FGSM testbed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.8/site-packages/torch/nn/_reduction.py:43: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dummy bit of code, the transfer attacks don't happen properly without this for some reason\n",
    "\n",
    "filename = 'exp3_neck2_2_head1'\n",
    "\n",
    "# Generate Head and Neck NN objects\n",
    "mode = 'cuda'\n",
    "head_nn = CNN_Head(mode)\n",
    "neck_nn = CNN_Neck(mode)\n",
    "\n",
    "# Which network to load and directory\n",
    "i = 0\n",
    "exp_path = \"Results/federated_system/\"+filename+\"/\"\n",
    "nn_path = exp_path + filename + \"_\"\n",
    "\n",
    "# Load pre-trained weights\n",
    "head_path = nn_path + str(i) +\"_head_network\"\n",
    "neck_path = nn_path + str(i) +\"_neck_network\"\n",
    "\n",
    "head = torch.load(head_path)\n",
    "neck = torch.load(neck_path)\n",
    "    \n",
    "head_edit = OrderedDict()\n",
    "neck_edit = OrderedDict()\n",
    "\n",
    "# Edit the ordered_dict key names to be torch compatible\n",
    "for key in head.keys():\n",
    "    head_edit[\"network.\"+key] = head[key]\n",
    "\n",
    "for key in neck.keys():\n",
    "    neck_edit[\"network.\"+key] = neck[key]\n",
    "\n",
    "head_nn.load_state_dict(head_edit)\n",
    "neck_nn.load_state_dict(neck_edit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load Config File and Slie Indices\n",
    "with open(r'config.yaml') as file:\n",
    "        config = yaml.load(file, Loader=yaml.FullLoader)\n",
    "        \n",
    "file_indices = [i for i in range(config['num_sets'])]\n",
    "#random.shuffle(file_indices)\n",
    "client_slice = len(file_indices)//config['num_clients']\n",
    "\n",
    "# File names of FL trained setting\n",
    "filenames = [\"exp3_neck2_0_head3\"]\n",
    "\n",
    "# Matrix to Record Performance\n",
    "orig_acc_transfers = np.zeros((1,config['num_clients']))\n",
    "orig_similarities = np.zeros((1,config['num_clients']))\n",
    "orig_target_hit = np.zeros((1,config['num_clients']))\n",
    "adv_acc_transfers = np.zeros((1,config['num_clients']))\n",
    "adv_similarities = np.zeros((1,config['num_clients']))\n",
    "adv_target_hit = np.zeros((1,config['num_clients']))\n",
    "\n",
    "# Attack Params\n",
    "batch_size = 100\n",
    "iteration = 10\n",
    "target = 5\n",
    "\n",
    "# IFGSM\n",
    "eps = 0.3\n",
    "alpha = 0.3\n",
    "\n",
    "# CWA\n",
    "confidence = 0\n",
    "optimizer_lr = 5e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic loader for generating the victim\n",
    "\n",
    "def load_victim(idx, loader):\n",
    "    # Load the corresponding head/neck network in victim nn module \n",
    "    \n",
    "    mode = 'cuda'\n",
    "    #head_nn = CNN_Head(mode)\n",
    "    #neck_nn = CNN_Neck(mode)\n",
    "    \n",
    "    # Which network to load and directory\n",
    "    exp_path = \"Results/federated_system/\"+filename+\"/\"\n",
    "    nn_path = exp_path + filename + \"_\"\n",
    "\n",
    "    # Load pre-trained weights\n",
    "    head_path = nn_path + str(idx) +\"_head_network\"\n",
    "    neck_path = nn_path + str(idx) +\"_neck_network\"\n",
    "\n",
    "    head = torch.load(head_path)\n",
    "    neck = torch.load(neck_path)\n",
    "\n",
    "    head_edit = OrderedDict()\n",
    "    neck_edit = OrderedDict()\n",
    "\n",
    "    # Edit the ordered_dict key names to be torch compatible\n",
    "    for key in head.keys():\n",
    "        head_edit[\"network.\"+key] = head[key]\n",
    "\n",
    "    for key in neck.keys():\n",
    "        neck_edit[\"network.\"+key] = neck[key]\n",
    "\n",
    "    head_nn.load_state_dict(head_edit)\n",
    "    neck_nn.load_state_dict(neck_edit)\n",
    "    \n",
    "    return Victim_NN(head_nn,neck_nn,loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform the transfer attack below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading  all_data_12_niid_0_keep_0_train_9.json\n",
      "Loading  all_data_20_niid_0_keep_0_train_9.json\n",
      "Loading  all_data_11_niid_0_keep_0_train_9.json\n",
      "Loading  all_data_18_niid_0_keep_0_train_9.json\n",
      "Using scale consts: [0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001]\n",
      "Using scale consts: [0.01, 0.0005, 0.01, 0.0005, 0.01, 0.0005, 0.01, 0.01, 0.0005, 0.01, 0.0005, 0.0005, 0.01, 0.0005, 0.01, 0.0005, 0.0005, 0.01, 0.01, 0.0005, 0.0005, 0.01, 0.01, 0.01, 0.01, 0.01, 0.0005, 0.01, 0.01, 0.01, 0.01, 0.0005, 0.0005, 0.0005, 0.01, 0.0005, 0.0005, 0.0005, 0.01, 0.01, 0.01, 0.0005, 0.01, 0.0005, 0.01, 0.01, 0.0005, 0.0005, 0.0005, 0.01, 0.0005, 0.0005, 0.01, 0.0005, 0.01, 0.01, 0.0005, 0.0005, 0.0005, 0.01, 0.01, 0.0005, 0.01, 0.0005, 0.01, 0.0005, 0.0005, 0.01, 0.01, 0.0005, 0.01, 0.0005, 0.0005, 0.01, 0.0005, 0.01, 0.0005, 0.01, 0.01, 0.0005, 0.0005, 0.01, 0.0005, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.0005, 0.0005, 0.01, 0.0005, 0.0005, 0.01, 0.01, 0.01, 0.0005, 0.0005, 0.0005]\n",
      "Using scale consts: [0.1, 0.00025, 0.1, 0.00025, 0.0055, 0.00025, 0.1, 0.1, 0.00025, 0.1, 0.00025, 0.00025, 0.1, 0.00025, 0.1, 0.00025, 0.00025, 0.1, 0.1, 0.00025, 0.00025, 0.1, 0.1, 0.1, 0.1, 0.1, 0.00025, 0.1, 0.1, 0.1, 0.1, 0.00025, 0.00025, 0.00025, 0.1, 0.00075, 0.00025, 0.00025, 0.1, 0.1, 0.1, 0.00025, 0.1, 0.00025, 0.1, 0.0055, 0.00025, 0.00025, 0.00025, 0.1, 0.00025, 0.00025, 0.1, 0.00025, 0.1, 0.1, 0.00025, 0.00025, 0.00025, 0.1, 0.0055, 0.00075, 0.1, 0.00025, 0.1, 0.00025, 0.00025, 0.1, 0.1, 0.00025, 0.1, 0.00025, 0.00025, 0.1, 0.00025, 0.1, 0.00025, 0.1, 0.0055, 0.00025, 0.00025, 0.1, 0.00025, 0.1, 0.1, 0.0055, 0.1, 0.0055, 0.1, 0.00025, 0.00025, 0.1, 0.00025, 0.00025, 0.1, 0.1, 0.0055, 0.00025, 0.00025, 0.00025]\n",
      "Using scale consts: [0.055, 0.000125, 0.055, 0.000125, 0.00775, 0.000125, 0.055, 0.055, 0.000125, 0.055, 0.000125, 0.000125, 0.055, 0.000125, 0.055, 0.000125, 0.000125, 1.0, 0.055, 0.000125, 0.000125, 0.055, 0.055, 0.055, 0.055, 1.0, 0.000125, 0.055, 0.055, 0.055, 0.055, 0.000125, 0.000125, 0.000125, 1.0, 0.000625, 0.000125, 0.000125, 1.0, 0.055, 0.055, 0.000125, 0.055, 0.000125, 0.055, 0.00325, 0.000125, 0.000125, 0.000125, 0.055, 0.000125, 0.000125, 0.055, 0.000125, 0.055, 0.055, 0.000125, 0.000125, 0.000125, 0.055, 0.00775, 0.000875, 0.055, 0.000125, 0.055, 0.000125, 0.000125, 0.055, 0.055, 0.000125, 0.055, 0.000125, 0.000125, 0.055, 0.000125, 0.055, 0.000125, 0.055, 0.00775, 0.000125, 0.000125, 0.055, 0.000125, 0.055, 0.055, 0.00775, 0.055, 0.00325, 1.0, 0.000125, 0.000125, 0.055, 0.000125, 0.000125, 1.0, 0.055, 0.00325, 0.000125, 0.000125, 0.000125]\n",
      "Using scale consts: [0.0325, 6.25e-05, 0.0325, 6.25e-05, 0.006625, 6.25e-05, 0.0325, 0.0325, 6.25e-05, 0.0325, 6.25e-05, 6.25e-05, 0.0775, 6.25e-05, 0.0325, 6.25e-05, 6.25e-05, 0.55, 0.0325, 6.25e-05, 6.25e-05, 0.0325, 0.0325, 0.0325, 0.0325, 0.55, 6.25e-05, 0.0325, 0.0325, 0.0325, 0.0325, 6.25e-05, 6.25e-05, 6.25e-05, 0.55, 0.0006875, 6.25e-05, 6.25e-05, 0.55, 0.0325, 0.0325, 0.0001875, 0.0325, 6.25e-05, 0.0325, 0.0043749999999999995, 6.25e-05, 6.25e-05, 6.25e-05, 0.0325, 6.25e-05, 6.25e-05, 0.0325, 6.25e-05, 0.0325, 0.0325, 6.25e-05, 6.25e-05, 6.25e-05, 0.0325, 0.006625, 0.0008125000000000001, 0.0325, 6.25e-05, 0.0325, 6.25e-05, 6.25e-05, 0.0325, 0.0325, 6.25e-05, 0.0325, 6.25e-05, 6.25e-05, 0.0325, 6.25e-05, 0.0325, 6.25e-05, 0.0775, 0.006625, 6.25e-05, 6.25e-05, 0.0325, 6.25e-05, 0.0325, 0.0325, 0.008875000000000001, 0.0325, 0.002125, 0.55, 6.25e-05, 6.25e-05, 0.0325, 6.25e-05, 6.25e-05, 0.55, 0.0775, 0.002125, 6.25e-05, 6.25e-05, 6.25e-05]\n",
      "Using scale consts: [0.02125, 3.125e-05, 0.04375, 3.125e-05, 0.0060625, 3.125e-05, 0.02125, 0.04375, 3.125e-05, 0.02125, 3.125e-05, 3.125e-05, 0.06625, 3.125e-05, 0.04375, 3.125e-05, 3.125e-05, 0.325, 0.02125, 3.125e-05, 3.125e-05, 0.04375, 0.04375, 0.02125, 0.02125, 0.325, 3.125e-05, 0.02125, 0.02125, 0.02125, 0.04375, 3.125e-05, 3.125e-05, 3.125e-05, 0.325, 0.0006562499999999999, 3.125e-05, 3.125e-05, 0.325, 0.02125, 0.02125, 0.00021875, 0.02125, 3.125e-05, 0.02125, 0.0038125, 3.125e-05, 3.125e-05, 3.125e-05, 0.02125, 3.125e-05, 3.125e-05, 0.04375, 3.125e-05, 0.02125, 0.02125, 3.125e-05, 3.125e-05, 3.125e-05, 0.02125, 0.0060625, 0.00078125, 0.02125, 3.125e-05, 0.04375, 3.125e-05, 3.125e-05, 0.04375, 0.04375, 3.125e-05, 0.02125, 3.125e-05, 3.125e-05, 0.02125, 3.125e-05, 0.02125, 3.125e-05, 0.06625, 0.0060625, 3.125e-05, 3.125e-05, 0.02125, 3.125e-05, 0.02125, 0.04375, 0.0083125, 0.02125, 0.0026875, 0.325, 3.125e-05, 3.125e-05, 0.02125, 3.125e-05, 3.125e-05, 0.325, 0.06625, 0.0026875, 3.125e-05, 3.125e-05, 3.125e-05]\n",
      "Using scale consts: [0.015625, 1.5625e-05, 0.038125, 1.5625e-05, 0.00578125, 1.5625e-05, 0.015625, 0.038125, 1.5625e-05, 0.015625, 1.5625e-05, 1.5625e-05, 0.060625, 1.5625e-05, 0.038125, 1.5625e-05, 1.5625e-05, 0.21250000000000002, 0.015625, 1.5625e-05, 1.5625e-05, 0.038125, 0.038125, 0.015625, 0.015625, 0.21250000000000002, 1.5625e-05, 0.015625, 0.015625, 0.015625, 0.038125, 1.5625e-05, 1.5625e-05, 1.5625e-05, 0.21250000000000002, 0.0006406249999999999, 1.5625e-05, 1.5625e-05, 0.21250000000000002, 0.015625, 0.015625, 0.000234375, 0.015625, 1.5625e-05, 0.026875000000000003, 0.0035312499999999997, 1.5625e-05, 1.5625e-05, 1.5625e-05, 0.015625, 1.5625e-05, 1.5625e-05, 0.038125, 1.5625e-05, 0.015625, 0.015625, 1.5625e-05, 1.5625e-05, 1.5625e-05, 0.015625, 0.00578125, 0.000765625, 0.015625, 1.5625e-05, 0.038125, 1.5625e-05, 1.5625e-05, 0.038125, 0.038125, 1.5625e-05, 0.015625, 1.5625e-05, 1.5625e-05, 0.026875000000000003, 1.5625e-05, 0.015625, 1.5625e-05, 0.060625, 0.00578125, 1.5625e-05, 1.5625e-05, 0.026875000000000003, 1.5625e-05, 0.015625, 0.038125, 0.00803125, 0.015625, 0.00240625, 0.21250000000000002, 1.5625e-05, 1.5625e-05, 0.015625, 1.5625e-05, 1.5625e-05, 0.21250000000000002, 0.060625, 0.00240625, 1.5625e-05, 1.5625e-05, 1.5625e-05]\n",
      "Using scale consts: [0.012812500000000001, 7.8125e-06, 0.0353125, 7.8125e-06, 0.005640625, 7.8125e-06, 0.012812500000000001, 0.0353125, 7.8125e-06, 0.012812500000000001, 7.8125e-06, 7.8125e-06, 0.0578125, 7.8125e-06, 0.0353125, 7.8125e-06, 7.8125e-06, 0.15625, 0.012812500000000001, 7.8125e-06, 7.8125e-06, 0.0353125, 0.0353125, 0.012812500000000001, 0.012812500000000001, 0.15625, 7.8125e-06, 0.012812500000000001, 0.012812500000000001, 0.012812500000000001, 0.0353125, 7.8125e-06, 7.8125e-06, 7.8125e-06, 0.15625, 0.0006328124999999999, 7.8125e-06, 7.8125e-06, 0.15625, 0.012812500000000001, 0.012812500000000001, 0.0002421875, 0.012812500000000001, 7.8125e-06, 0.0240625, 0.0033906249999999995, 7.8125e-06, 7.8125e-06, 7.8125e-06, 0.012812500000000001, 7.8125e-06, 7.8125e-06, 0.0353125, 7.8125e-06, 0.012812500000000001, 0.012812500000000001, 7.8125e-06, 7.8125e-06, 7.8125e-06, 0.012812500000000001, 0.005640625, 0.0007578125, 0.012812500000000001, 7.8125e-06, 0.0353125, 7.8125e-06, 7.8125e-06, 0.0353125, 0.0353125, 7.8125e-06, 0.012812500000000001, 7.8125e-06, 7.8125e-06, 0.0240625, 7.8125e-06, 0.012812500000000001, 7.8125e-06, 0.0578125, 0.005640625, 7.8125e-06, 7.8125e-06, 0.0240625, 7.8125e-06, 0.012812500000000001, 0.0353125, 0.007890625, 0.012812500000000001, 0.0022656250000000003, 0.15625, 7.8125e-06, 7.8125e-06, 0.012812500000000001, 7.8125e-06, 7.8125e-06, 0.15625, 0.0578125, 0.0022656250000000003, 7.8125e-06, 7.8125e-06, 7.8125e-06]\n",
      "Using scale consts: [0.01140625, 3.90625e-06, 0.03390625, 3.90625e-06, 0.0055703125, 3.90625e-06, 0.01140625, 0.03390625, 3.90625e-06, 0.01140625, 3.90625e-06, 3.90625e-06, 0.056406250000000005, 3.90625e-06, 0.03390625, 3.90625e-06, 3.90625e-06, 0.128125, 0.01140625, 3.90625e-06, 3.90625e-06, 0.03390625, 0.03390625, 0.01140625, 0.01140625, 0.128125, 3.90625e-06, 0.01140625, 0.01140625, 0.01140625, 0.03390625, 3.90625e-06, 3.90625e-06, 3.90625e-06, 0.128125, 0.0006289062499999999, 3.90625e-06, 3.90625e-06, 0.128125, 0.01140625, 0.01140625, 0.00024609375, 0.01140625, 3.90625e-06, 0.022656250000000003, 0.0033203124999999995, 3.90625e-06, 3.90625e-06, 3.90625e-06, 0.01140625, 3.90625e-06, 3.90625e-06, 0.03390625, 3.90625e-06, 0.01140625, 0.01140625, 3.90625e-06, 3.90625e-06, 3.90625e-06, 0.01140625, 0.0055703125, 0.00075390625, 0.01140625, 3.90625e-06, 0.03390625, 3.90625e-06, 3.90625e-06, 0.03390625, 0.03390625, 3.90625e-06, 0.01140625, 3.90625e-06, 3.90625e-06, 0.022656250000000003, 3.90625e-06, 0.01140625, 3.90625e-06, 0.056406250000000005, 0.0055703125, 3.90625e-06, 3.90625e-06, 0.022656250000000003, 3.90625e-06, 0.01140625, 0.03390625, 0.0078203125, 0.01140625, 0.0021953125, 0.128125, 3.90625e-06, 3.90625e-06, 0.01140625, 3.90625e-06, 3.90625e-06, 0.128125, 0.056406250000000005, 0.0021953125, 3.90625e-06, 3.90625e-06, 3.90625e-06]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using scale consts: [0.01140625, 3.90625e-06, 0.03390625, 3.90625e-06, 0.0055703125, 3.90625e-06, 0.01140625, 0.03390625, 3.90625e-06, 0.01140625, 3.90625e-06, 3.90625e-06, 0.056406250000000005, 3.90625e-06, 0.03390625, 3.90625e-06, 3.90625e-06, 0.128125, 0.01140625, 3.90625e-06, 3.90625e-06, 0.03390625, 0.03390625, 0.01140625, 0.01140625, 0.128125, 3.90625e-06, 0.01140625, 0.01140625, 0.01140625, 0.03390625, 3.90625e-06, 3.90625e-06, 3.90625e-06, 0.128125, 0.0006289062499999999, 3.90625e-06, 3.90625e-06, 0.128125, 0.01140625, 0.01140625, 0.00024609375, 0.01140625, 3.90625e-06, 0.022656250000000003, 0.0033203124999999995, 3.90625e-06, 3.90625e-06, 3.90625e-06, 0.01140625, 3.90625e-06, 3.90625e-06, 0.03390625, 3.90625e-06, 0.01140625, 0.01140625, 3.90625e-06, 3.90625e-06, 3.90625e-06, 0.01140625, 0.0055703125, 0.00075390625, 0.01140625, 3.90625e-06, 0.03390625, 3.90625e-06, 3.90625e-06, 0.03390625, 0.03390625, 3.90625e-06, 0.01140625, 3.90625e-06, 3.90625e-06, 0.022656250000000003, 3.90625e-06, 0.01140625, 3.90625e-06, 0.056406250000000005, 0.0055703125, 3.90625e-06, 3.90625e-06, 0.022656250000000003, 3.90625e-06, 0.01140625, 0.03390625, 0.0078203125, 0.01140625, 0.0021953125, 0.128125, 3.90625e-06, 3.90625e-06, 0.01140625, 3.90625e-06, 3.90625e-06, 0.128125, 0.056406250000000005, 0.0021953125, 3.90625e-06, 3.90625e-06, 3.90625e-06]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Could not run 'aten::conj.out' with arguments from the 'CUDATensorId' backend. 'aten::conj.out' is only available for these backends: [CPUTensorId, VariableTensorId].",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-4f125d0a81af>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;31m# Generate adversarial Perturbations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     victim_source.CW_attack(batch_size = batch_size, target= target, confidence=confidence, \n\u001b[0m\u001b[1;32m     12\u001b[0m                             \u001b[0moptimizer_lr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer_lr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miteration\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0miteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_val_mean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m                             x_val_std= (0.5), print_info=False)\n",
      "\u001b[0;32m<ipython-input-3-b61cac4b7aff>\u001b[0m in \u001b[0;36mCW_attack\u001b[0;34m(self, batch_size, target, confidence, optimizer_lr, iteration, x_val_mean, x_val_std, print_info)\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx_adv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx_orig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspecs_from_xadv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprint_info\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-b61cac4b7aff>\u001b[0m in \u001b[0;36mspecs_from_xadv\u001b[0;34m(self, print_info)\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m         \u001b[0;31m# Add Perturbation Distance (L2 norm) - across each input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx_orig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx_adv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m         \u001b[0;31m# Print Relevant Information\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/functional.py\u001b[0m in \u001b[0;36mnorm\u001b[0;34m(input, p, dim, keepdim, out, dtype)\u001b[0m\n\u001b[1;32m    753\u001b[0m             \u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    754\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 755\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_VariableFunctions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrobenius_norm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkeepdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    756\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_VariableFunctions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrobenius_norm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkeepdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    757\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mp\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"nuc\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Could not run 'aten::conj.out' with arguments from the 'CUDATensorId' backend. 'aten::conj.out' is only available for these backends: [CPUTensorId, VariableTensorId]."
     ]
    }
   ],
   "source": [
    "for source in range(1):\n",
    "    \n",
    "    # Bring in the data loader for this client\n",
    "    loader = Dataloader(file_indices,[source*(client_slice),min((source+1)*(client_slice),35)])  \n",
    "    loader.load_training_dataset()\n",
    "    loader.load_testing_dataset()\n",
    "\n",
    "    victim_source = load_victim(source,loader)\n",
    "\n",
    "    # Generate adversarial Perturbations\n",
    "    victim_source.CW_attack(batch_size = batch_size, target= target, confidence=confidence, \n",
    "                            optimizer_lr=optimizer_lr, iteration=iteration, x_val_mean = (0.5), \n",
    "                            x_val_std= (0.5), print_info=False)\n",
    "\n",
    "    # Record relevant tensors\n",
    "    x_orig = victim_source.x_orig\n",
    "    y_orig = victim_source.output_orig\n",
    "    y_true = victim_source.y_orig\n",
    "    x_adv = victim_source.x_adv\n",
    "    y_adv = victim_source.output_adv\n",
    "\n",
    "    print(\"======== Source\", source, \"========\")\n",
    "\n",
    "    for dest in range(config['num_clients']):\n",
    "\n",
    "        print(\"    ==== Dest\", dest, \"====\")\n",
    "\n",
    "        victim_dest = load_victim(dest,loader)\n",
    "\n",
    "        # Compute Stats and record\n",
    "        victim_dest.forward_transfer(x_orig,x_adv,y_orig,y_adv,y_true, target, print_info=True)\n",
    "\n",
    "        orig_acc_transfers[source,dest] = victim_dest.orig_test_acc\n",
    "        orig_similarities[source,dest] = victim_dest.orig_output_sim\n",
    "        orig_target_hit[source,dest] = victim_dest.orig_target_achieve\n",
    "\n",
    "        adv_acc_transfers[source,dest] = victim_dest.adv_test_acc\n",
    "        adv_similarities[source,dest] = victim_dest.adv_output_sim\n",
    "        adv_target_hit[source,dest] = victim_dest.adv_target_achieve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"orig_acc_transfers\\n\",np.round(orig_acc_transfers,3)[0])\n",
    "print(\"orig_similarities\\n\",np.round(orig_similarities,3))\n",
    "print(\"orig_target_hit\\n\",np.round(orig_target_hit,3))\n",
    "print(\"adv_acc_transfers\\n\",np.round(adv_acc_transfers,3))\n",
    "print(\"adv_similarities\\n\",np.round(adv_similarities,3))\n",
    "print(\"adv_target_hit\\n\",np.round(adv_target_hit,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "victim_source.orig_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "victim_source.adv_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
