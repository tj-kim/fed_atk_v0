{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transferability Metrics\n",
    "\n",
    "TJ Kim <br/>\n",
    "2/4/21\n",
    "\n",
    "Updated <br/>\n",
    "2/21/21\n",
    "\n",
    "#### Objective: \n",
    "To the existing (and functioning) FGSM attack, add measurements of transferability between different networks.\n",
    "This will help us compare as well. \n",
    "\n",
    "#### Transferability Metrics\n",
    "- Size of input gradient\n",
    "- Gradient Alignment\n",
    "- Variance of Loss\n",
    "\n",
    "#### Other Metrics\n",
    "- Confidence of attack (Loss towards target)\n",
    "- L2 Distance from original point\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/FedAtk\n"
     ]
    }
   ],
   "source": [
    "cd '/home/ubuntu/FedAtk/' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Relevant Libraries and Modules\n",
    "\n",
    "Load the relevant libraries for the federated learning code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Personal NN\n",
    "from transfer_attacks.Personalized_NN import *\n",
    "\n",
    "# Import the Rest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metric Callers\n",
    "\n",
    "This will go inside a new PY file that calls individual metric calculations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import torch\n",
    "\n",
    "def calcNN_variance(network, data_x, data_y):\n",
    "    \"\"\"\n",
    "    Take in Pytorch nn module (surrogate)\n",
    "    and data loader tensor data in order to obtain variance of loss across empirical distribution\n",
    "    \"\"\"\n",
    "    \n",
    "    network.eval()\n",
    "    \n",
    "    loss_func = torch.nn.NLLLoss(reduction='none')\n",
    "    loss = loss_func(network(data_x), data_y)\n",
    "    EL1 = torch.mean(torch.mul(loss,loss))\n",
    "    EL2 = torch.mul(torch.mean(loss),torch.mean(loss))\n",
    "    \n",
    "    return torch.sub(EL1, EL2)\n",
    "\n",
    "def calcNN_alignment(network1, network2, data_x, data_y):\n",
    "    \"\"\"\n",
    "    Take in surrogate and victim pytorch nn module, as well as dataloader tensor inputs\n",
    "    \"\"\"\n",
    "    network1.eval()\n",
    "    network2.eval()\n",
    "    network1.zero_grad()\n",
    "    network2.zero_grad()\n",
    "    \n",
    "    # Obtain gradient with respect to each input\n",
    "    x_adv1 = Variable(data_x, requires_grad=True)\n",
    "    h_adv1 = network1.forward(x_adv1)\n",
    "    cost1 = network1.criterion(h_adv1, data_y)\n",
    "    \n",
    "    x_adv2 = Variable(data_x, requires_grad=True)\n",
    "    h_adv2 = network2.forward(x_adv2)\n",
    "    cost2 = network2.criterion(h_adv2, data_y)\n",
    "    \n",
    "    if x_adv1.grad is not None:\n",
    "        x_adv1.grad.data.fill_(0)\n",
    "    if x_adv2.grad is not None:\n",
    "        x_adv2.grad.data.fill_(0)\n",
    "    cost1.backward()\n",
    "    cost2.backward()\n",
    "    \n",
    "    # Loop through each input and calculate norm\n",
    "    temp = torch.zeros((x_adv1.shape[0],28,28))\n",
    "    for i in range(x_adv1.shape[0]):\n",
    "        \n",
    "        num = torch.matmul(torch.transpose(x_adv1.grad[i,0.:,:], 0, 1),x_adv2.grad[i,0.:,:])\n",
    "        den = torch.norm(input= x_adv1.grad[i,0,:,:],p=2) * torch.norm(input= x_adv2.grad[i,0,:,:],p=2)\n",
    "        \n",
    "        temp[i,:,:] = num/den\n",
    "        \n",
    "    return temp\n",
    "\n",
    "def calcNN_ingrad(network, data_x, data_y, norm=2):\n",
    "    \"\"\"\n",
    "    Take in pytorch nn module (victim)\n",
    "    and data tensor to obtain size of input gradient \n",
    "    \"\"\"\n",
    "    \n",
    "    network.eval()\n",
    "    \n",
    "    # Obtain gradient with respect to each input\n",
    "    x_adv = Variable(data_x, requires_grad=True)\n",
    "    h_adv = network.forward(x_adv)\n",
    "    cost = network.criterion(h_adv, data_y)\n",
    "    \n",
    "    network.zero_grad()\n",
    "\n",
    "    if x_adv.grad is not None:\n",
    "        x_adv.grad.data.fill_(0)\n",
    "    cost.backward()\n",
    "    \n",
    "    # Loop through each input and calculate norm\n",
    "    temp = torch.zeros(x_adv.shape[0])\n",
    "    for i in range(x_adv.shape[0]):\n",
    "        temp[i] = torch.norm(input= x_adv.grad[i,0,:,:],p=norm)\n",
    "    \n",
    "    # Find mean of Norms\n",
    "    return torch.mean(temp)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transferer\n",
    "\n",
    "Copy existing transferer here and work on calling the metric calculations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "# Import Custom Made Victim\n",
    "from transfer_attacks.Personalized_NN import *\n",
    "from transfer_attacks.Params import *\n",
    "            \n",
    "class Transferer(): \n",
    "    \"\"\"\n",
    "    - Collect all the FL NN \n",
    "    - Implement transfer attack sweep\n",
    "    - Hold all the metrics of interest\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, filename:str, config_name = None):\n",
    "        \n",
    "        # TO IMPLEMENT - Overwrite current file with config_name\n",
    "        with open(r'configs/config.yaml') as file:\n",
    "            self.config = yaml.load(file, Loader=yaml.FullLoader)\n",
    "            \n",
    "        self.file = filename\n",
    "        \n",
    "        # Matrix to Record Performance (Old Metrics)\n",
    "        self.orig_acc_transfers = {}\n",
    "        self.orig_similarities = {}\n",
    "        self.orig_target_hit = {}\n",
    "        self.adv_acc_transfers = {}\n",
    "        self.adv_similarities = {}\n",
    "        self.adv_target_hit = {}\n",
    "        \n",
    "        # Matrix to Record Performance (New Metrics - theoretical)\n",
    "        \n",
    "        # Attack Params\n",
    "        self.ifsgm_params = IFSGM_Params()\n",
    "        self.cw_params = CW_Params()\n",
    "        \n",
    "        # Other Params\n",
    "        self.advNN_idx = None # int\n",
    "        self.advNN = None # pytorch nn\n",
    "        self.victim_idxs = None # List of ints\n",
    "        self.victims = None # dict of pytorch nn\n",
    "        \n",
    "        # Recorded Data Points\n",
    "        self.x_orig = None\n",
    "        self.y_orig = None\n",
    "        self.y_true = None\n",
    "        self.x_adv = None\n",
    "        self.y_adv = None\n",
    "        \n",
    "        # Transferability Metrics\n",
    "        self.metric_variance = None # Single value\n",
    "        self.metric_alignment = {} # Dict - key is victim NN id\n",
    "        self.metric_ingrad = {} # Dict - key is victim NN id\n",
    "        \n",
    "    def generate_advNN(self, client_idx):\n",
    "        \"\"\"\n",
    "        Select specific client to load neural network to \n",
    "        Load the data for that client\n",
    "        Lod the weights for that client\n",
    "        This is the client that will generate perturbations\n",
    "        \"\"\"\n",
    "        \n",
    "        # Import Data Loader for this FL set\n",
    "        file_indices = [i for i in range(self.config['num_sets'])]\n",
    "        client_slice = len(file_indices)//self.config['num_clients']\n",
    "        \n",
    "        # Import the loader for this dataset only\n",
    "        self.loader = Dataloader(file_indices,[client_idx*(client_slice),min((client_idx+1)*(client_slice),35)])  \n",
    "        self.loader.load_training_dataset()\n",
    "        self.loader.load_testing_dataset()\n",
    "        \n",
    "        self.advNN_idx = client_idx\n",
    "        self.advNN = load_FLNN(idx=client_idx, direc=self.file, loader=self.loader)\n",
    "        \n",
    "        return\n",
    "    \n",
    "    def generate_xadv(self, atk_type = \"IFSGM\"):\n",
    "        \"\"\"\n",
    "        Generate perturbed images\n",
    "        atk_type - \"IFSGM\" or \"CW\"\n",
    "        \"\"\"\n",
    "        \n",
    "        if (atk_type == \"IFSGM\") or (atk_type == \"ifsgm\"): \n",
    "            self.advNN.i_fgsm(self.ifsgm_params)\n",
    "        elif (atk_type == \"CW\") or (atk_type == \"cw\"):\n",
    "            self.advNN.CW_attack(self.cw_params)\n",
    "        else:\n",
    "            print(\"Attak type unidentified -- Running IFSGM\")\n",
    "            self.advNN.i_fgsm(self.ifsgm_params)\n",
    "        \n",
    "        # Record relevant tensors\n",
    "        self.x_orig = self.advNN.x_orig\n",
    "        self.y_orig = self.advNN.output_orig\n",
    "        self.y_true = self.advNN.y_orig\n",
    "        self.x_adv = self.advNN.x_adv\n",
    "        self.y_adv = self.advNN.output_adv\n",
    "    \n",
    "    def generate_victims(self, client_idxs):\n",
    "        \"\"\"\n",
    "        Load the pre-trained other clients in the system\n",
    "        \"\"\"\n",
    "        \n",
    "        self.victim_idxs = client_idxs\n",
    "        self.victims = {}\n",
    "    \n",
    "        for i in self.victim_idxs:\n",
    "            self.victims[i] = load_FLNN(idx=i, direc=self.file, loader=None)\n",
    "    \n",
    "    def send_to_victims(self, client_idxs):\n",
    "        \"\"\"\n",
    "        Send pre-generated adversarial perturbations \n",
    "        client_idxs - list of indices of clients we want to attack (just victims)\n",
    "        \n",
    "        Then record the attack success stats accordingly\n",
    "        \"\"\"\n",
    "        \n",
    "        for i in client_idxs:\n",
    "            self.victims[i].forward_transfer(self.x_orig,self.x_adv,\n",
    "                                         self.y_orig,self.y_adv,\n",
    "                                         self.y_true, self.ifsgm_params.target, \n",
    "                                         print_info=False)\n",
    "            \n",
    "            # Record Performance\n",
    "            self.orig_acc_transfers[i] = self.victims[i].orig_test_acc\n",
    "            self.orig_similarities[i] = self.victims[i].orig_output_sim\n",
    "            self.orig_target_hit[i] = self.victims[i].orig_target_achieve\n",
    "\n",
    "            self.adv_acc_transfers[i] = self.victims[i].adv_test_acc\n",
    "            self.adv_similarities[i] = self.victims[i].adv_output_sim\n",
    "            self.adv_target_hit[i] = self.victims[i].adv_target_achieve\n",
    "            \n",
    "    def check_empirical_metrics(self, orig_flag = True, batch_size = 1000):\n",
    "        \"\"\"\n",
    "        Computes the following for the following models:\n",
    "        - Size of input gradient - across data distribution across all victim NN\n",
    "        - Gradient Alignment - Between the surrogate and each of the victim NN\n",
    "        - Variance of loss - Just for the surrogate\n",
    "        \n",
    "        - Orig flag false uses new fresh data as inputs instead of xorig and yorig\n",
    "          (used to attack victims)\n",
    "        \"\"\"\n",
    "        \n",
    "        # Load a Sample of data from the datalaoder\n",
    "        if not orig_flag:\n",
    "            image_data = self.advNN.dataloader.load_batch(batch_size)\n",
    "            data_x  = torch.Tensor(image_data['input']).reshape(batch_size,1,28,28)\n",
    "            data_y = torch.Tensor(image_data['label']).type(torch.LongTensor)\n",
    "\n",
    "            if torch.cuda.is_available():\n",
    "                data_y = data_y.cuda()\n",
    "        else:\n",
    "            data_x = self.x_orig\n",
    "            data_y = self.y_orig\n",
    "        \n",
    "        self.metric_variance = calcNN_variance(self.advNN, data_x, data_y)\n",
    "        for i in range(len(self.victims)):\n",
    "            self.metric_alignment[i] = calcNN_alignment(self.advNN, self.victims[i], data_x, data_y) \n",
    "            self.metric_ingrad[i] = calcNN_ingrad(self.victims[i],data_x,data_y) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and Run the System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "client_idx = 0\n",
    "victim_idxs = [0,1,2,3,4,5,6,7]\n",
    "\n",
    "# Generate NN and Victims\n",
    "#transferer = Transferer(filename = 'exp2_neck2_head3')\n",
    "#transferer.generate_advNN(client_idx = client_idx)\n",
    "transferer.generate_victims(client_idxs = victim_idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "transferer.generate_xadv(atk_type = \"ifsgm\")\n",
    "transferer.send_to_victims(victim_idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0588, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "{0: tensor([6.5118e-02, 3.7973e+00, 1.4780e-01, 2.4235e+00, 3.7102e-01, 1.4618e-03,\n",
      "        1.5876e-02, 2.8617e-02, 9.4379e-06, 1.6888e-01]), 1: tensor([7.8913e-02, 8.7229e+00, 8.0429e-02, 2.7824e+00, 1.4411e+00, 2.0141e-02,\n",
      "        8.7402e-02, 4.8293e-02, 2.5223e-07, 8.7618e-01]), 2: tensor([2.9426e-02, 8.9910e+00, 1.1845e-01, 6.5815e+00, 1.1847e+00, 4.4809e-02,\n",
      "        6.8365e-02, 1.6138e-01, 2.5911e-05, 7.0737e-02]), 3: tensor([2.4195e-01, 3.2880e+00, 6.4686e-01, 1.1122e+00, 1.9353e-02, 2.8432e-02,\n",
      "        3.4569e-02, 3.6026e-02, 9.2752e-07, 1.1626e-01]), 4: tensor([1.4387e-01, 9.4165e+00, 6.8067e-02, 6.7760e+00, 1.1161e+00, 1.9865e-02,\n",
      "        1.1960e-01, 1.8354e+00, 1.1989e-06, 2.7010e-01]), 5: tensor([1.7159e-01, 9.2250e+00, 5.3784e-01, 6.6097e+00, 1.4966e+00, 1.1977e-01,\n",
      "        2.3251e-01, 4.4481e-02, 6.1137e-06, 6.3884e-01]), 6: tensor([1.6446e-02, 4.1397e+00, 1.7222e-01, 2.4781e+00, 2.2540e+00, 2.1469e-02,\n",
      "        1.0356e-01, 2.0167e-01, 2.7634e-05, 5.6652e-02]), 7: tensor([5.3130e-03, 7.7749e+00, 1.3866e+00, 1.5531e+00, 5.3430e-01, 7.3752e-02,\n",
      "        1.2241e-01, 1.3114e-02, 6.0788e-04, 4.6617e-01])}\n"
     ]
    }
   ],
   "source": [
    "# Run the empirical metrics\n",
    "transferer.check_empirical_metrics(orig_flag = True, batch_size = 10)\n",
    "print(transferer.metric_variance)\n",
    "print(transferer.metric_ingrad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 9,  6,  1, 36, 36,  1,  1, 39,  4,  5], device='cuda:0')\n",
      "tensor([ 9,  4,  1,  4, 36,  1,  1, 39,  4,  5], device='cuda:0')\n",
      "tensor([ 9,  4,  1,  4, 36,  1,  1, 39,  4,  5], device='cuda:0')\n",
      "tensor([ 9,  6,  1, 36, 36,  1,  1, 39,  4,  5], device='cuda:0')\n",
      "tensor([ 9,  4,  1,  4, 36,  1,  1, 39,  4,  5], device='cuda:0')\n",
      "tensor([ 9,  4,  1,  4, 36,  1,  1, 39,  4,  5], device='cuda:0')\n",
      "tensor([ 9,  6,  1,  0,  2,  1,  1, 39,  4,  5], device='cuda:0')\n",
      "tensor([ 9,  4, 47, 36, 36,  1,  1, 39,  4,  5], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "for i in range(8):\n",
    "    print(torch.argmax(transferer.victims[i](transferer.x_orig),dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([20, 20, 20, 20, 20, 20, 20, 20, 20, 20], device='cuda:0')\n",
      "tensor([20, 20, 20, 20, 20, 20, 20, 23, 20,  5], device='cuda:0')\n",
      "tensor([20, 20, 20, 46, 46, 20, 46, 17,  4, 20], device='cuda:0')\n",
      "tensor([20, 20, 20, 20, 20, 20, 20, 23, 20, 20], device='cuda:0')\n",
      "tensor([20, 20, 20, 20, 20, 20, 20,  6, 20,  5], device='cuda:0')\n",
      "tensor([20, 20, 20,  4, 20, 20, 20, 46,  4,  5], device='cuda:0')\n",
      "tensor([20, 20, 20, 23, 20, 20, 20, 30, 20,  5], device='cuda:0')\n",
      "tensor([ 4, 20, 20, 27, 20, 20, 20, 23,  4, 20], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "for i in range(8):\n",
    "    print(torch.argmax(transferer.victims[i](transferer.x_adv),dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " NN 0\n",
      "orig_acc_transfers:  tensor(0.8000, device='cuda:0')\n",
      "orig_similarities:  tensor(1., device='cuda:0')\n",
      "orig_target_hit: tensor(0., device='cuda:0')\n",
      "adv_acc_transfers: tensor(0., device='cuda:0')\n",
      "adv_similarities: tensor(1., device='cuda:0')\n",
      "adv_target_hit: tensor(1., device='cuda:0')\n",
      "\n",
      " NN 1\n",
      "orig_acc_transfers:  tensor(0.7000, device='cuda:0')\n",
      "orig_similarities:  tensor(0.8000, device='cuda:0')\n",
      "orig_target_hit: tensor(0., device='cuda:0')\n",
      "adv_acc_transfers: tensor(0.1000, device='cuda:0')\n",
      "adv_similarities: tensor(0.8000, device='cuda:0')\n",
      "adv_target_hit: tensor(0.8000, device='cuda:0')\n",
      "\n",
      " NN 2\n",
      "orig_acc_transfers:  tensor(0.7000, device='cuda:0')\n",
      "orig_similarities:  tensor(0.8000, device='cuda:0')\n",
      "orig_target_hit: tensor(0., device='cuda:0')\n",
      "adv_acc_transfers: tensor(0.1000, device='cuda:0')\n",
      "adv_similarities: tensor(0.5000, device='cuda:0')\n",
      "adv_target_hit: tensor(0.5000, device='cuda:0')\n",
      "\n",
      " NN 3\n",
      "orig_acc_transfers:  tensor(0.8000, device='cuda:0')\n",
      "orig_similarities:  tensor(1., device='cuda:0')\n",
      "orig_target_hit: tensor(0., device='cuda:0')\n",
      "adv_acc_transfers: tensor(0., device='cuda:0')\n",
      "adv_similarities: tensor(0.9000, device='cuda:0')\n",
      "adv_target_hit: tensor(0.9000, device='cuda:0')\n",
      "\n",
      " NN 4\n",
      "orig_acc_transfers:  tensor(0.7000, device='cuda:0')\n",
      "orig_similarities:  tensor(0.8000, device='cuda:0')\n",
      "orig_target_hit: tensor(0., device='cuda:0')\n",
      "adv_acc_transfers: tensor(0.1000, device='cuda:0')\n",
      "adv_similarities: tensor(0.8000, device='cuda:0')\n",
      "adv_target_hit: tensor(0.8000, device='cuda:0')\n",
      "\n",
      " NN 5\n",
      "orig_acc_transfers:  tensor(0.7000, device='cuda:0')\n",
      "orig_similarities:  tensor(0.8000, device='cuda:0')\n",
      "orig_target_hit: tensor(0., device='cuda:0')\n",
      "adv_acc_transfers: tensor(0.2000, device='cuda:0')\n",
      "adv_similarities: tensor(0.6000, device='cuda:0')\n",
      "adv_target_hit: tensor(0.6000, device='cuda:0')\n",
      "\n",
      " NN 6\n",
      "orig_acc_transfers:  tensor(0.7000, device='cuda:0')\n",
      "orig_similarities:  tensor(0.8000, device='cuda:0')\n",
      "orig_target_hit: tensor(0., device='cuda:0')\n",
      "adv_acc_transfers: tensor(0.1000, device='cuda:0')\n",
      "adv_similarities: tensor(0.7000, device='cuda:0')\n",
      "adv_target_hit: tensor(0.7000, device='cuda:0')\n",
      "\n",
      " NN 7\n",
      "orig_acc_transfers:  tensor(0.6000, device='cuda:0')\n",
      "orig_similarities:  tensor(0.8000, device='cuda:0')\n",
      "orig_target_hit: tensor(0., device='cuda:0')\n",
      "adv_acc_transfers: tensor(0.1000, device='cuda:0')\n",
      "adv_similarities: tensor(0.6000, device='cuda:0')\n",
      "adv_target_hit: tensor(0.6000, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "for j in range(8):\n",
    "    print(\"\\n NN\", j)\n",
    "    print(\"orig_acc_transfers: \",transferer.orig_acc_transfers[j])\n",
    "    print(\"orig_similarities: \",transferer.orig_similarities[j])\n",
    "    print(\"orig_target_hit:\",transferer.orig_target_hit[j])\n",
    "    print(\"adv_acc_transfers:\",transferer.adv_acc_transfers[j])\n",
    "    print(\"adv_similarities:\",transferer.adv_similarities[j])\n",
    "    print(\"adv_target_hit:\",transferer.adv_target_hit[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
