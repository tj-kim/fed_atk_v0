{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transferability Metrics\n",
    "\n",
    "TJ Kim <br/>\n",
    "2/4/21\n",
    "\n",
    "Updated <br/>\n",
    "2/21/21\n",
    "\n",
    "#### Objective: \n",
    "To the existing (and functioning) FGSM attack, add measurements of transferability between different networks.\n",
    "This will help us compare as well. \n",
    "\n",
    "#### Transferability Metrics\n",
    "- Size of input gradient\n",
    "- Gradient Alignment\n",
    "- Variance of Loss\n",
    "\n",
    "#### Other Metrics\n",
    "- Confidence of attack (Loss towards target)\n",
    "- L2 Distance from original point\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/FedAtk\n"
     ]
    }
   ],
   "source": [
    "cd '/home/ubuntu/FedAtk/' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Relevant Libraries and Modules\n",
    "\n",
    "Load the relevant libraries for the federated learning code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Personal NN\n",
    "from transfer_attacks.Personalized_NN import *\n",
    "\n",
    "# Import the Rest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metric Callers\n",
    "\n",
    "This will go inside a new PY file that calls individual metric calculations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import torch\n",
    "\n",
    "def calcNN_variance(network, data_x, data_y):\n",
    "    \"\"\"\n",
    "    Take in Pytorch nn module (surrogate)\n",
    "    and data loader tensor data in order to obtain variance of loss across empirical distribution\n",
    "    \"\"\"\n",
    "    \n",
    "    network.eval()\n",
    "    \n",
    "    loss_func = torch.nn.NLLLoss(reduction='none')\n",
    "    loss = loss_func(network(data_x), data_y)\n",
    "    EL1 = torch.mean(torch.mul(loss,loss))\n",
    "    EL2 = torch.mul(torch.mean(loss),torch.mean(loss))\n",
    "    \n",
    "    return torch.sub(EL1, EL2)\n",
    "\n",
    "def calcNN_alignment(network1, network2, data_x, data_y):\n",
    "    \"\"\"\n",
    "    Take in surrogate and victim pytorch nn module, as well as dataloader tensor inputs\n",
    "    \"\"\"\n",
    "    network1.eval()\n",
    "    network2.eval()\n",
    "    network1.zero_grad()\n",
    "    network2.zero_grad()\n",
    "    \n",
    "    # Obtain gradient with respect to each input\n",
    "    x_adv1 = Variable(data_x, requires_grad=True)\n",
    "    h_adv1 = network1.forward(x_adv1)\n",
    "    cost1 = network1.criterion(h_adv1, data_y)\n",
    "    \n",
    "    x_adv2 = Variable(data_x, requires_grad=True)\n",
    "    h_adv2 = network2.forward(x_adv2)\n",
    "    cost2 = network2.criterion(h_adv2, data_y)\n",
    "    \n",
    "    if x_adv1.grad is not None:\n",
    "        x_adv1.grad.data.fill_(0)\n",
    "    if x_adv2.grad is not None:\n",
    "        x_adv2.grad.data.fill_(0)\n",
    "    cost1.backward()\n",
    "    cost2.backward()\n",
    "    \n",
    "    # Loop through each input and calculate norm\n",
    "    temp = torch.zeros(x_adv1.shape[0])\n",
    "    for i in range(x_adv1.shape[0]):\n",
    "        \n",
    "        # Reshape numerator matrices into vectors to end up with scalar\n",
    "        g1 = torch.reshape(x_adv1.grad[i,0,:,:],(torch.numel(x_adv1.grad[i,0,:,:]),1))\n",
    "        g2 = torch.reshape(x_adv2.grad[i,0,:,:],(torch.numel(x_adv2.grad[i,0,:,:]),1))\n",
    "        \n",
    "        num = torch.matmul(torch.transpose(g1, 0, 1),g2)\n",
    "        den = torch.norm(input= x_adv1.grad[i,0,:,:],p=2) * torch.norm(input= x_adv2.grad[i,0,:,:],p=2)\n",
    "        \n",
    "        temp[i] = num/den\n",
    "        \n",
    "    return torch.acos(torch.mean(temp))\n",
    "\n",
    "def calcNN_ingrad(network, data_x, data_y, norm=2):\n",
    "    \"\"\"\n",
    "    Take in pytorch nn module (victim)\n",
    "    and data tensor to obtain size of input gradient \n",
    "    \"\"\"\n",
    "    \n",
    "    network.eval()\n",
    "    \n",
    "    # Obtain gradient with respect to each input\n",
    "    x_adv = Variable(data_x, requires_grad=True)\n",
    "    h_adv = network.forward(x_adv)\n",
    "    cost = network.criterion(h_adv, data_y)\n",
    "    \n",
    "    network.zero_grad()\n",
    "\n",
    "    if x_adv.grad is not None:\n",
    "        x_adv.grad.data.fill_(0)\n",
    "    cost.backward()\n",
    "    \n",
    "    # Loop through each input and calculate norm\n",
    "    temp = torch.zeros(x_adv.shape[0])\n",
    "    for i in range(x_adv.shape[0]):\n",
    "        temp[i] = torch.norm(input= x_adv.grad[i,0,:,:],p=norm)\n",
    "    \n",
    "    # Find mean of Norms\n",
    "    return torch.mean(temp)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transferer\n",
    "\n",
    "Copy existing transferer here and work on calling the metric calculations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "# Import Custom Made Victim\n",
    "from transfer_attacks.Personalized_NN import *\n",
    "from transfer_attacks.Params import *\n",
    "            \n",
    "class Transferer(): \n",
    "    \"\"\"\n",
    "    - Collect all the FL NN \n",
    "    - Implement transfer attack sweep\n",
    "    - Hold all the metrics of interest\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, filename:str, config_name = None):\n",
    "        \n",
    "        # TO IMPLEMENT - Overwrite current file with config_name\n",
    "        with open(r'configs/config.yaml') as file:\n",
    "            self.config = yaml.load(file, Loader=yaml.FullLoader)\n",
    "            \n",
    "        self.file = filename\n",
    "        \n",
    "        # Matrix to Record Performance (Old Metrics)\n",
    "        self.orig_acc_transfers = {}\n",
    "        self.orig_similarities = {}\n",
    "        self.orig_target_hit = {}\n",
    "        self.adv_acc_transfers = {}\n",
    "        self.adv_similarities = {}\n",
    "        self.adv_target_hit = {}\n",
    "        \n",
    "        # Matrix to Record Performance (New Metrics - theoretical)\n",
    "        \n",
    "        # Attack Params\n",
    "        self.ifsgm_params = IFSGM_Params()\n",
    "        self.cw_params = CW_Params()\n",
    "        \n",
    "        # Other Params\n",
    "        self.advNN_idx = None # int\n",
    "        self.advNN = None # pytorch nn\n",
    "        self.victim_idxs = None # List of ints\n",
    "        self.victims = None # dict of pytorch nn\n",
    "        \n",
    "        # Recorded Data Points\n",
    "        self.x_orig = None\n",
    "        self.y_orig = None\n",
    "        self.y_true = None\n",
    "        self.x_adv = None\n",
    "        self.y_adv = None\n",
    "        \n",
    "        # Transferability Metrics\n",
    "        self.metric_variance = None # Single value\n",
    "        self.metric_alignment = {} # Dict - key is victim NN id\n",
    "        self.metric_ingrad = {} # Dict - key is victim NN id\n",
    "        \n",
    "    def generate_advNN(self, client_idx):\n",
    "        \"\"\"\n",
    "        Select specific client to load neural network to \n",
    "        Load the data for that client\n",
    "        Lod the weights for that client\n",
    "        This is the client that will generate perturbations\n",
    "        \"\"\"\n",
    "        \n",
    "        # Import Data Loader for this FL set\n",
    "        file_indices = [i for i in range(self.config['num_sets'])]\n",
    "        client_slice = len(file_indices)//self.config['num_clients']\n",
    "        \n",
    "        # Import the loader for this dataset only\n",
    "        self.loader = Dataloader(file_indices,[client_idx*(client_slice),min((client_idx+1)*(client_slice),35)])  \n",
    "        self.loader.load_training_dataset()\n",
    "        self.loader.load_testing_dataset()\n",
    "        \n",
    "        self.advNN_idx = client_idx\n",
    "        self.advNN = load_FLNN(idx=client_idx, direc=self.file, loader=self.loader)\n",
    "        \n",
    "        return\n",
    "    \n",
    "    def generate_xadv(self, atk_type = \"IFSGM\"):\n",
    "        \"\"\"\n",
    "        Generate perturbed images\n",
    "        atk_type - \"IFSGM\" or \"CW\"\n",
    "        \"\"\"\n",
    "        \n",
    "        if (atk_type == \"IFSGM\") or (atk_type == \"ifsgm\"): \n",
    "            self.advNN.i_fgsm(self.ifsgm_params)\n",
    "        elif (atk_type == \"CW\") or (atk_type == \"cw\"):\n",
    "            self.advNN.CW_attack(self.cw_params)\n",
    "        else:\n",
    "            print(\"Attak type unidentified -- Running IFSGM\")\n",
    "            self.advNN.i_fgsm(self.ifsgm_params)\n",
    "        \n",
    "        # Record relevant tensors\n",
    "        self.x_orig = self.advNN.x_orig\n",
    "        self.y_orig = self.advNN.output_orig\n",
    "        self.y_true = self.advNN.y_orig\n",
    "        self.x_adv = self.advNN.x_adv\n",
    "        self.y_adv = self.advNN.output_adv\n",
    "    \n",
    "    def generate_victims(self, client_idxs):\n",
    "        \"\"\"\n",
    "        Load the pre-trained other clients in the system\n",
    "        \"\"\"\n",
    "        \n",
    "        self.victim_idxs = client_idxs\n",
    "        self.victims = {}\n",
    "    \n",
    "        for i in self.victim_idxs:\n",
    "            self.victims[i] = load_FLNN(idx=i, direc=self.file, loader=None)\n",
    "    \n",
    "    def send_to_victims(self, client_idxs):\n",
    "        \"\"\"\n",
    "        Send pre-generated adversarial perturbations \n",
    "        client_idxs - list of indices of clients we want to attack (just victims)\n",
    "        \n",
    "        Then record the attack success stats accordingly\n",
    "        \"\"\"\n",
    "        \n",
    "        for i in client_idxs:\n",
    "            self.victims[i].forward_transfer(self.x_orig,self.x_adv,\n",
    "                                         self.y_orig,self.y_adv,\n",
    "                                         self.y_true, self.ifsgm_params.target, \n",
    "                                         print_info=False)\n",
    "            \n",
    "            # Record Performance\n",
    "            self.orig_acc_transfers[i] = self.victims[i].orig_test_acc\n",
    "            self.orig_similarities[i] = self.victims[i].orig_output_sim\n",
    "            self.orig_target_hit[i] = self.victims[i].orig_target_achieve\n",
    "\n",
    "            self.adv_acc_transfers[i] = self.victims[i].adv_test_acc\n",
    "            self.adv_similarities[i] = self.victims[i].adv_output_sim\n",
    "            self.adv_target_hit[i] = self.victims[i].adv_target_achieve\n",
    "            \n",
    "    def check_empirical_metrics(self, orig_flag = True, batch_size = 1000):\n",
    "        \"\"\"\n",
    "        Computes the following for the following models:\n",
    "        - Size of input gradient - across data distribution across all victim NN\n",
    "        - Gradient Alignment - Between the surrogate and each of the victim NN\n",
    "        - Variance of loss - Just for the surrogate\n",
    "        \n",
    "        - Orig flag false uses new fresh data as inputs instead of xorig and yorig\n",
    "          (used to attack victims)\n",
    "        \"\"\"\n",
    "        \n",
    "        # Load a Sample of data from the datalaoder\n",
    "        if not orig_flag:\n",
    "            image_data = self.advNN.dataloader.load_batch(batch_size)\n",
    "            data_x  = torch.Tensor(image_data['input']).reshape(batch_size,1,28,28)\n",
    "            data_y = torch.Tensor(image_data['label']).type(torch.LongTensor)\n",
    "\n",
    "            if torch.cuda.is_available():\n",
    "                data_y = data_y.cuda()\n",
    "        else:\n",
    "            data_x = self.x_orig\n",
    "            data_y = self.y_orig\n",
    "        \n",
    "        self.metric_variance = calcNN_variance(self.advNN, data_x, data_y)\n",
    "        for i in range(len(self.victims)):\n",
    "            self.metric_alignment[i] = calcNN_alignment(self.advNN, self.victims[i], data_x, data_y) \n",
    "            self.metric_ingrad[i] = calcNN_ingrad(self.victims[i],data_x,data_y) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and Run the System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading  all_data_12_niid_0_keep_0_train_9.json\n",
      "Loading  all_data_20_niid_0_keep_0_train_9.json\n",
      "Loading  all_data_11_niid_0_keep_0_train_9.json\n",
      "Loading  all_data_18_niid_0_keep_0_train_9.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.8/site-packages/torch/nn/_reduction.py:43: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    }
   ],
   "source": [
    "client_idx = 0\n",
    "victim_idxs = [0,1,2,3,4,5,6,7]\n",
    "\n",
    "# Generate NN and Victims\n",
    "transferer = Transferer(filename = 'exp2_neck2_head3')\n",
    "transferer.generate_advNN(client_idx = client_idx)\n",
    "transferer.generate_victims(client_idxs = victim_idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "transferer.generate_xadv(atk_type = \"ifsgm\")\n",
    "transferer.send_to_victims(victim_idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.5511,  0.8382,  0.5994,  0.5947, -0.1246,  0.6078,  0.6414,  0.4547,\n",
      "         0.5584,  0.4835])\n"
     ]
    }
   ],
   "source": [
    "# Run the empirical metrics\n",
    "transferer.check_empirical_metrics(orig_flag = True, batch_size = 10)\n",
    "#print(transferer.metric_variance)\n",
    "#print(transferer.metric_ingrad)\n",
    "print(transferer.metric_alignment[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([15, 14, 39, 24, 46, 53,  4, 28, 56, 25], device='cuda:0')\n",
      "tensor([15, 14, 39, 24, 46, 53,  4, 28, 30, 15], device='cuda:0')\n",
      "tensor([15, 14, 39, 24, 46, 53,  4, 28, 30, 25], device='cuda:0')\n",
      "tensor([15, 14, 39, 24, 43, 53,  4, 28, 30, 15], device='cuda:0')\n",
      "tensor([15, 14, 39,  0, 46, 53,  4, 54, 56, 25], device='cuda:0')\n",
      "tensor([15, 14, 39, 24, 43, 53,  4, 28, 30, 25], device='cuda:0')\n",
      "tensor([14, 14, 39, 24, 46, 53,  4, 28, 56, 25], device='cuda:0')\n",
      "tensor([15, 14, 39, 24, 43, 53,  4, 28, 30, 25], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "for i in range(8):\n",
    "    print(torch.argmax(transferer.victims[i](transferer.x_orig),dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([20, 20, 20, 20, 20, 20, 20, 20, 20, 20], device='cuda:0')\n",
      "tensor([20, 20, 23, 20, 20, 20, 20, 20, 20, 15], device='cuda:0')\n",
      "tensor([34, 46, 17, 20, 20, 20, 17, 15, 46, 25], device='cuda:0')\n",
      "tensor([20, 20, 20, 20, 20, 20, 20, 20, 20, 20], device='cuda:0')\n",
      "tensor([20, 20,  4, 20, 20, 20, 20, 20, 20, 14], device='cuda:0')\n",
      "tensor([20, 20, 23, 20, 20, 20, 60, 20, 20, 15], device='cuda:0')\n",
      "tensor([20, 20,  4, 20, 20, 20, 20, 20, 20, 15], device='cuda:0')\n",
      "tensor([20, 20,  4,  4, 20, 20,  4, 20, 20, 20], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "for i in range(8):\n",
    "    print(torch.argmax(transferer.victims[i](transferer.x_adv),dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " NN 0\n",
      "orig_acc_transfers:  tensor(0.9000, device='cuda:0')\n",
      "orig_similarities:  tensor(1., device='cuda:0')\n",
      "orig_target_hit: tensor(0., device='cuda:0')\n",
      "adv_acc_transfers: tensor(0.1000, device='cuda:0')\n",
      "adv_similarities: tensor(1., device='cuda:0')\n",
      "adv_target_hit: tensor(1., device='cuda:0')\n",
      "\n",
      " NN 1\n",
      "orig_acc_transfers:  tensor(0.7000, device='cuda:0')\n",
      "orig_similarities:  tensor(0.8000, device='cuda:0')\n",
      "orig_target_hit: tensor(0., device='cuda:0')\n",
      "adv_acc_transfers: tensor(0.1000, device='cuda:0')\n",
      "adv_similarities: tensor(0.8000, device='cuda:0')\n",
      "adv_target_hit: tensor(0.8000, device='cuda:0')\n",
      "\n",
      " NN 2\n",
      "orig_acc_transfers:  tensor(0.8000, device='cuda:0')\n",
      "orig_similarities:  tensor(0.9000, device='cuda:0')\n",
      "orig_target_hit: tensor(0., device='cuda:0')\n",
      "adv_acc_transfers: tensor(0.2000, device='cuda:0')\n",
      "adv_similarities: tensor(0.3000, device='cuda:0')\n",
      "adv_target_hit: tensor(0.3000, device='cuda:0')\n",
      "\n",
      " NN 3\n",
      "orig_acc_transfers:  tensor(0.7000, device='cuda:0')\n",
      "orig_similarities:  tensor(0.7000, device='cuda:0')\n",
      "orig_target_hit: tensor(0., device='cuda:0')\n",
      "adv_acc_transfers: tensor(0.1000, device='cuda:0')\n",
      "adv_similarities: tensor(1., device='cuda:0')\n",
      "adv_target_hit: tensor(1., device='cuda:0')\n",
      "\n",
      " NN 4\n",
      "orig_acc_transfers:  tensor(0.7000, device='cuda:0')\n",
      "orig_similarities:  tensor(0.8000, device='cuda:0')\n",
      "orig_target_hit: tensor(0., device='cuda:0')\n",
      "adv_acc_transfers: tensor(0.1000, device='cuda:0')\n",
      "adv_similarities: tensor(0.8000, device='cuda:0')\n",
      "adv_target_hit: tensor(0.8000, device='cuda:0')\n",
      "\n",
      " NN 5\n",
      "orig_acc_transfers:  tensor(0.8000, device='cuda:0')\n",
      "orig_similarities:  tensor(0.8000, device='cuda:0')\n",
      "orig_target_hit: tensor(0., device='cuda:0')\n",
      "adv_acc_transfers: tensor(0.1000, device='cuda:0')\n",
      "adv_similarities: tensor(0.7000, device='cuda:0')\n",
      "adv_target_hit: tensor(0.7000, device='cuda:0')\n",
      "\n",
      " NN 6\n",
      "orig_acc_transfers:  tensor(0.8000, device='cuda:0')\n",
      "orig_similarities:  tensor(0.9000, device='cuda:0')\n",
      "orig_target_hit: tensor(0., device='cuda:0')\n",
      "adv_acc_transfers: tensor(0.1000, device='cuda:0')\n",
      "adv_similarities: tensor(0.8000, device='cuda:0')\n",
      "adv_target_hit: tensor(0.8000, device='cuda:0')\n",
      "\n",
      " NN 7\n",
      "orig_acc_transfers:  tensor(0.8000, device='cuda:0')\n",
      "orig_similarities:  tensor(0.8000, device='cuda:0')\n",
      "orig_target_hit: tensor(0., device='cuda:0')\n",
      "adv_acc_transfers: tensor(0.2000, device='cuda:0')\n",
      "adv_similarities: tensor(0.7000, device='cuda:0')\n",
      "adv_target_hit: tensor(0.7000, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "for j in range(8):\n",
    "    print(\"\\n NN\", j)\n",
    "    print(\"orig_acc_transfers: \",transferer.orig_acc_transfers[j])\n",
    "    print(\"orig_similarities: \",transferer.orig_similarities[j])\n",
    "    print(\"orig_target_hit:\",transferer.orig_target_hit[j])\n",
    "    print(\"adv_acc_transfers:\",transferer.adv_acc_transfers[j])\n",
    "    print(\"adv_similarities:\",transferer.adv_similarities[j])\n",
    "    print(\"adv_target_hit:\",transferer.adv_target_hit[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
