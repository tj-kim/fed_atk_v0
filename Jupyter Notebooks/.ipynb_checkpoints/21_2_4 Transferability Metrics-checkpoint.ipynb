{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transferability Metrics\n",
    "\n",
    "TJ Kim <br/>\n",
    "2/4/21\n",
    "\n",
    "#### Objective: \n",
    "To the existing (and functioning) FGSM attack, add measurements of transferability between different networks.\n",
    "This will help us compare as well. \n",
    "\n",
    "#### Transferability Metrics\n",
    "- Size of input gradient\n",
    "- Gradient Alignment\n",
    "- Variance of Loss\n",
    "\n",
    "#### Other Metrics\n",
    "- Confidence of attack (Loss towards target)\n",
    "- L2 Distance from original point\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/FedAtk\n"
     ]
    }
   ],
   "source": [
    "cd '/home/ubuntu/FedAtk/' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Relevant Libraries and Modules\n",
    "\n",
    "Load the relevant libraries for the federated learning code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import yaml\n",
    "        \n",
    "from femnist_dataloader import Dataloader\n",
    "from cnn_head import CNN_Head\n",
    "from cnn_neck import CNN_Neck\n",
    "from cnn_server import Server\n",
    "from cnn_client import Client\n",
    "from data_manager import DataManager\n",
    "from utils import cuda, where\n",
    "\n",
    "from utilities import freeze_layers\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import csv\n",
    "import os\n",
    "import pickle\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import multiprocessing as mp\n",
    "\n",
    "import queue\n",
    "\n",
    "# Extra not from py file\n",
    "from collections import OrderedDict \n",
    "import itertools\n",
    "\n",
    "from __future__ import print_function\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Victim NN\n",
    "\n",
    "This is the victim NN class. We will install the transferability metric measures here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Victim_NN(nn.Module):\n",
    "    \"\"\"\n",
    "    Summary: \n",
    "    \n",
    "    Pytorch NN module that takes pre-trained weights from layered personalized model\n",
    "    We also load the data-loader and give test,attack functionality\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, head_network, neck_network, dataloader):\n",
    "        \n",
    "        # Init attributes\n",
    "        super(Victim_NN, self).__init__()\n",
    "        self.head = head_network\n",
    "        self.neck = neck_network\n",
    "        self.dataloader = dataloader\n",
    "        self.criterion = nn.NLLLoss()\n",
    "        \n",
    "        # test_acc attributes\n",
    "        self.orig_test_acc = None\n",
    "        self.adv_test_acc = None\n",
    "        \n",
    "        self.orig_output_sim = None\n",
    "        self.adv_output_sim = None\n",
    "        \n",
    "        # I_FGSM attributes\n",
    "        self.x_orig = None\n",
    "        self.x_adv = None\n",
    "        self.y_orig = None\n",
    "        self.target = None\n",
    "        \n",
    "        self.softmax_orig = None\n",
    "        self.output_orig = None\n",
    "        self.softmax_adv = None\n",
    "        self.output_adv = None\n",
    "        \n",
    "        self.orig_loss = None\n",
    "        self.adv_loss = None\n",
    "        self.orig_acc = None\n",
    "        self.adv_acc = None\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.neck.forward(x)\n",
    "        x = self.head.forward(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    def forward_transfer(self, x_orig, x_adv, y_orig, y_adv,\n",
    "                         true_labels, target, print_info = False):\n",
    "        \"\"\"\n",
    "        Assume that input images are in pytorch tensor format\n",
    "        \"\"\"\n",
    "        \n",
    "        batch_size = y_orig.shape[0]\n",
    "        \n",
    "        # Forward Two Input Types\n",
    "        h_adv = self.forward(x_adv)\n",
    "        h_orig = self.forward(x_orig)\n",
    "        h_adv_category = torch.argmax(h_adv,dim = 1)\n",
    "        h_orig_category = torch.argmax(h_orig,dim = 1)\n",
    "        \n",
    "        # Record Different Parameters\n",
    "        self.orig_test_acc = (h_orig_category == true_labels).float().sum()/batch_size\n",
    "        self.adv_test_acc = (h_adv_category == true_labels).float().sum()/batch_size\n",
    "        \n",
    "        self.orig_output_sim = (h_orig_category == y_orig).float().sum()/batch_size\n",
    "        self.adv_output_sim = (h_adv_category == y_adv).float().sum()/batch_size\n",
    "        \n",
    "        self.orig_target_achieve = (h_orig_category == target).float().sum()/batch_size\n",
    "        self.adv_target_achieve = (h_adv_category == target).float().sum()/batch_size\n",
    "\n",
    "        \n",
    "        # Print Relevant Information\n",
    "        if print_info:\n",
    "            print(\"---- Attack Transfer:\", \"----\\n\")\n",
    "            print(\"         Orig Test Acc:\", self.orig_test_acc.item())\n",
    "            print(\"          Adv Test Acc:\", self.adv_test_acc.item())\n",
    "            print(\"Orig Output Similarity:\", self.orig_output_sim.item())\n",
    "            print(\" Adv Output Similarity:\", self.adv_output_sim.item())\n",
    "            print(\"       Orig Target Hit:\", self.orig_target_achieve.item())\n",
    "            print(\"        Adv Target Hit:\", self.adv_target_achieve.item())\n",
    "        \n",
    "    def i_fgsm(self, batch_size = 10, target= -1, eps=0.03, alpha=1, \n",
    "               iteration=1, x_val_min=-1, x_val_max=1, print_info=False):\n",
    "        \"\"\"\n",
    "        batch_size - number of images to adversarially perturb\n",
    "        targetted - target class output we desire to alter all inputs into\n",
    "        eps - max amount to add perturbations per pixel per iteration\n",
    "        alpha - gradient scaling (increase minimum perturbation amount below epsilon)\n",
    "        iteration - how many times to perturb\n",
    "        x_val_min/max - NN input valid range to keep perturbations within\n",
    "        \"\"\"\n",
    "        self.eval()\n",
    "        \n",
    "        # Load data to perturb\n",
    "    \n",
    "        image_data = self.dataloader.load_batch(batch_size)\n",
    "        self.x_orig  = torch.Tensor(image_data['input']).reshape(batch_size,1,28,28)\n",
    "        self.y_orig = torch.Tensor(image_data['label']).type(torch.LongTensor).cuda()\n",
    "        self.target = target\n",
    "        \n",
    "        self.x_adv = Variable(self.x_orig, requires_grad=True)\n",
    "        \n",
    "        for i in range(iteration):\n",
    "            \n",
    "            h_adv = self.forward(self.x_adv)\n",
    "            \n",
    "            # Loss function based on target\n",
    "            if target > -1:\n",
    "                target_tensor = torch.LongTensor(self.y_orig.size()).fill_(target)\n",
    "                target_tensor = Variable(cuda(target_tensor, self.cuda), requires_grad=False)\n",
    "                cost = self.criterion(h_adv, target_tensor)\n",
    "            else:\n",
    "                cost = -self.criterion(h_adv, self.y_orig)\n",
    "\n",
    "            self.zero_grad()\n",
    "\n",
    "            if self.x_adv.grad is not None:\n",
    "                self.x_adv.grad.data.fill_(0)\n",
    "            cost.backward()\n",
    "\n",
    "            self.x_adv.grad.sign_()\n",
    "            self.x_adv = self.x_adv - alpha*self.x_adv.grad\n",
    "            self.x_adv = where(self.x_adv > self.x_orig+eps, self.x_orig+eps, self.x_adv)\n",
    "            self.x_adv = where(self.x_adv < self.x_orig-eps, self.x_orig-eps, self.x_adv)\n",
    "            self.x_adv = torch.clamp(self.x_adv, x_val_min, x_val_max)\n",
    "            self.x_adv = Variable(self.x_adv.data, requires_grad=True)\n",
    "\n",
    "        self.softmax_orig = self.forward(self.x_orig)\n",
    "        self.output_orig = torch.argmax(self.softmax_orig,dim=1)\n",
    "        self.softmax_adv = self.forward(self.x_adv)\n",
    "        self.output_adv = torch.argmax(self.softmax_adv,dim=1)\n",
    "        \n",
    "        # Record accuracy and loss\n",
    "        self.orig_loss = self.criterion(self.softmax_orig, self.y_orig).item()\n",
    "        self.adv_loss = self.criterion(self.softmax_adv, self.y_orig).item()\n",
    "        self.orig_acc = (self.output_orig == self.y_orig).float().sum()/batch_size\n",
    "        self.adv_acc = (self.output_adv == self.y_orig).float().sum()/batch_size\n",
    "        \n",
    "        # Add Perturbation Distance (L2 norm) - across each input\n",
    "        self.norm = torch.norm(torch.sub(self.x_orig, self.x_adv, alpha=1),dim=(2,3))\n",
    "\n",
    "        # Print Relevant Information\n",
    "        if print_info:\n",
    "            print(\"---- FGSM Batch Size:\", batch_size, \"----\\n\")\n",
    "            print(\"Orig Target:\", self.y_orig.tolist())\n",
    "            print(\"Orig Output:\", self.output_orig.tolist())\n",
    "            print(\"ADV Output :\", self.output_adv.tolist(),'\\n')\n",
    "            print(\"Orig Loss  :\", self.orig_loss)\n",
    "            print(\"ADV Loss   :\", self.adv_loss,'\\n')\n",
    "            print(\"Orig Acc   :\", self.orig_acc.item())\n",
    "            print(\"ADV Acc    :\", self.adv_acc.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
