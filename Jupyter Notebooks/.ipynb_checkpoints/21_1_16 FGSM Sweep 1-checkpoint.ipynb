{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FGSM Sweep 1\n",
    "\n",
    "TJ Kim <br/>\n",
    "1/16/21\n",
    "\n",
    "#### Objective: \n",
    "Run FGSM attack on different number of head layers in federated learning and observe performance,\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/FedAtk\n"
     ]
    }
   ],
   "source": [
    "cd '/home/ubuntu/FedAtk/' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Relevant Libraries and Modules\n",
    "\n",
    "Load the relevant libraries for the federated learning code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import yaml\n",
    "        \n",
    "from federated_training.femnist_dataloader import Dataloader\n",
    "from federated_training.cnn_head import CNN_Head\n",
    "from federated_training.cnn_neck import CNN_Neck\n",
    "from federated_training.cnn_server import Server\n",
    "from federated_training.cnn_client import Client\n",
    "from federated_training.data_manager import DataManager\n",
    "from federated_training.utils import cuda, where\n",
    "\n",
    "from federated_training.utilities import freeze_layers\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import csv\n",
    "import os\n",
    "import pickle\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import multiprocessing as mp\n",
    "\n",
    "import queue\n",
    "\n",
    "# Extra not from py file\n",
    "from collections import OrderedDict \n",
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the relevant libraries for example FGSM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Import Custom Made Victim\n",
    "from transfer_attacks.victim_nn import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transfer Attack Sweeping Different Configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Config File and Slie Indices\n",
    "with open(r'configs/config.yaml') as file:\n",
    "        config = yaml.load(file, Loader=yaml.FullLoader)\n",
    "        \n",
    "file_indices = [i for i in range(config['num_sets'])]\n",
    "#random.shuffle(file_indices)\n",
    "client_slice = len(file_indices)//config['num_clients']\n",
    "\n",
    "# File names of FL trained setting\n",
    "filenames = [\"exp2_neck2_head1\", \"exp2_neck2_head2\",\n",
    "             \"exp2_neck2_head3\", \"exp2_neck2_head4\"]\n",
    "\n",
    "# Matrix to Record Performance\n",
    "orig_acc_transfers = np.zeros((1,config['num_clients']))\n",
    "orig_similarities = np.zeros((1,config['num_clients']))\n",
    "orig_target_hit = np.zeros((1,config['num_clients']))\n",
    "adv_acc_transfers = np.zeros((1,config['num_clients']))\n",
    "adv_similarities = np.zeros((1,config['num_clients']))\n",
    "adv_target_hit = np.zeros((1,config['num_clients']))\n",
    "\n",
    "# Attack Params\n",
    "batch_size = 1000\n",
    "eps = 0.5\n",
    "alpha = 0.5\n",
    "iteration = 30\n",
    "target = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading  all_data_12_niid_0_keep_0_train_9.json\n",
      "Loading  all_data_20_niid_0_keep_0_train_9.json\n",
      "Loading  all_data_11_niid_0_keep_0_train_9.json\n",
      "Loading  all_data_18_niid_0_keep_0_train_9.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.8/site-packages/torch/nn/_reduction.py:43: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======== Source 0 ========\n",
      "    ==== Dest 0 ====\n",
      "---- Attack Transfer: ----\n",
      "\n",
      "         Orig Test Acc: 0.9130000472068787\n",
      "          Adv Test Acc: 0.08400000631809235\n",
      "Orig Output Similarity: 0.984000027179718\n",
      " Adv Output Similarity: 0.12200000882148743\n",
      "       Orig Target Hit: 0.006000000052154064\n",
      "        Adv Target Hit: 0.03200000151991844\n",
      "    ==== Dest 1 ====\n",
      "---- Attack Transfer: ----\n",
      "\n",
      "         Orig Test Acc: 0.8180000185966492\n",
      "          Adv Test Acc: 0.09100000560283661\n",
      "Orig Output Similarity: 0.8540000319480896\n",
      " Adv Output Similarity: 0.07900000363588333\n",
      "       Orig Target Hit: 0.004000000189989805\n",
      "        Adv Target Hit: 0.018000001087784767\n",
      "    ==== Dest 2 ====\n",
      "---- Attack Transfer: ----\n",
      "\n",
      "         Orig Test Acc: 0.7750000357627869\n",
      "          Adv Test Acc: 0.09400000423192978\n",
      "Orig Output Similarity: 0.8110000491142273\n",
      " Adv Output Similarity: 0.09200000762939453\n",
      "       Orig Target Hit: 0.006000000052154064\n",
      "        Adv Target Hit: 0.02500000037252903\n",
      "    ==== Dest 3 ====\n",
      "---- Attack Transfer: ----\n",
      "\n",
      "         Orig Test Acc: 0.8360000252723694\n",
      "          Adv Test Acc: 0.08100000023841858\n",
      "Orig Output Similarity: 0.8600000143051147\n",
      " Adv Output Similarity: 0.08900000154972076\n",
      "       Orig Target Hit: 0.007000000216066837\n",
      "        Adv Target Hit: 0.03400000184774399\n",
      "    ==== Dest 4 ====\n",
      "---- Attack Transfer: ----\n",
      "\n",
      "         Orig Test Acc: 0.734000027179718\n",
      "          Adv Test Acc: 0.0950000062584877\n",
      "Orig Output Similarity: 0.7670000195503235\n",
      " Adv Output Similarity: 0.07900000363588333\n",
      "       Orig Target Hit: 0.006000000052154064\n",
      "        Adv Target Hit: 0.009000000543892384\n",
      "    ==== Dest 5 ====\n",
      "---- Attack Transfer: ----\n",
      "\n",
      "         Orig Test Acc: 0.7880000472068787\n",
      "          Adv Test Acc: 0.0950000062584877\n",
      "Orig Output Similarity: 0.8110000491142273\n",
      " Adv Output Similarity: 0.07800000160932541\n",
      "       Orig Target Hit: 0.004000000189989805\n",
      "        Adv Target Hit: 0.015000000596046448\n",
      "    ==== Dest 6 ====\n",
      "---- Attack Transfer: ----\n",
      "\n",
      "         Orig Test Acc: 0.8090000152587891\n",
      "          Adv Test Acc: 0.0860000029206276\n",
      "Orig Output Similarity: 0.8460000157356262\n",
      " Adv Output Similarity: 0.07700000703334808\n",
      "       Orig Target Hit: 0.007000000216066837\n",
      "        Adv Target Hit: 0.018000001087784767\n",
      "    ==== Dest 7 ====\n",
      "---- Attack Transfer: ----\n",
      "\n",
      "         Orig Test Acc: 0.8440000414848328\n",
      "          Adv Test Acc: 0.08500000089406967\n",
      "Orig Output Similarity: 0.8700000643730164\n",
      " Adv Output Similarity: 0.07300000637769699\n",
      "       Orig Target Hit: 0.007000000216066837\n",
      "        Adv Target Hit: 0.020000001415610313\n"
     ]
    }
   ],
   "source": [
    "file = 'exp2_neck2_head3'\n",
    "\n",
    "for source in range(1):\n",
    "    \n",
    "    # Bring in the data loader for this client\n",
    "    loader = Dataloader(file_indices,[source*(client_slice),min((source+1)*(client_slice),35)])  \n",
    "    loader.load_training_dataset()\n",
    "    loader.load_testing_dataset()\n",
    "\n",
    "    victim_source = load_victim(source,loader,file)\n",
    "\n",
    "    # Generate adversarial Perturbations\n",
    "    victim_source.i_fgsm(batch_size = batch_size, target= target, eps=eps, alpha=alpha, \n",
    "               iteration=iteration, x_val_min=-1, x_val_max=1, print_info=False)\n",
    "\n",
    "    # Record relevant tensors\n",
    "    x_orig = victim_source.x_orig\n",
    "    y_orig = victim_source.output_orig\n",
    "    y_true = victim_source.y_orig\n",
    "    x_adv = victim_source.x_adv\n",
    "    y_adv = victim_source.output_adv\n",
    "\n",
    "    print(\"======== Source\", source, \"========\")\n",
    "\n",
    "    for dest in range(config['num_clients']):\n",
    "\n",
    "        print(\"    ==== Dest\", dest, \"====\")\n",
    "\n",
    "        victim_dest = load_victim(dest,loader,file)\n",
    "\n",
    "        # Compute Stats and record\n",
    "        victim_dest.forward_transfer(x_orig,x_adv,y_orig,y_adv,y_true, target, print_info=True)\n",
    "\n",
    "        orig_acc_transfers[source,dest] = victim_dest.orig_test_acc\n",
    "        orig_similarities[source,dest] = victim_dest.orig_output_sim\n",
    "        orig_target_hit[source,dest] = victim_dest.orig_target_achieve\n",
    "\n",
    "        adv_acc_transfers[source,dest] = victim_dest.adv_test_acc\n",
    "        adv_similarities[source,dest] = victim_dest.adv_output_sim\n",
    "        adv_target_hit[source,dest] = victim_dest.adv_target_achieve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"orig_acc_transfers\\n\",np.round(orig_acc_transfers,3)[0])\n",
    "print(\"orig_similarities\\n\",np.round(orig_similarities,3))\n",
    "print(\"orig_target_hit\\n\",np.round(orig_target_hit,3))\n",
    "print(\"adv_acc_transfers\\n\",np.round(adv_acc_transfers,3))\n",
    "print(\"adv_similarities\\n\",np.round(adv_similarities,3))\n",
    "print(\"adv_target_hit\\n\",np.round(adv_target_hit,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
