{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FGSM Sweep 1\n",
    "\n",
    "TJ Kim <br/>\n",
    "1/16/21\n",
    "\n",
    "#### Objective: \n",
    "Run FGSM attack on different number of head layers in federated learning and observe performance,\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/FedAtk\n"
     ]
    }
   ],
   "source": [
    "cd '/home/ubuntu/FedAtk/' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Relevant Libraries and Modules\n",
    "\n",
    "Load the relevant libraries for the federated learning code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import yaml\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import csv\n",
    "import os\n",
    "import pickle\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import multiprocessing as mp\n",
    "import queue\n",
    "\n",
    "# Extra not from py file\n",
    "from collections import OrderedDict \n",
    "import itertools\n",
    "\n",
    "from __future__ import print_function\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Import Custom Made Victim\n",
    "from transfer_attacks.victim_nn import *\n",
    "\n",
    "# Federated Learning Module        \n",
    "from federated_training.femnist_dataloader import Dataloader\n",
    "from federated_training.cnn_head import CNN_Head\n",
    "from federated_training.cnn_neck import CNN_Neck\n",
    "from federated_training.cnn_server import Server\n",
    "from federated_training.cnn_client import Client\n",
    "from federated_training.data_manager import DataManager\n",
    "from federated_training.utils import cuda, where\n",
    "\n",
    "from federated_training.utilities import freeze_layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transfer Attack Sweeping Different Configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IFSGM_Params():\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        # Attack Params\n",
    "        self.batch_size = 1000\n",
    "        self.eps = 0.5\n",
    "        self.alpha = 0.5\n",
    "        self.iteration = 30\n",
    "        self.target = 10\n",
    "\n",
    "class Transferer(): \n",
    "    \"\"\"\n",
    "    - Collect all the FL NN \n",
    "    - Implement transfer attack sweep\n",
    "    - Hold all the metrics of interest\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, filename:str, config_name = None):\n",
    "        \n",
    "        # TO IMPLEMENT - Overwrite current file with config_name\n",
    "        with open(r'configs/config.yaml') as file:\n",
    "            self.config = yaml.load(file, Loader=yaml.FullLoader)\n",
    "            \n",
    "        self.file = filename\n",
    "            \n",
    "        # Import Data Loader for this FL set\n",
    "        file_indices = [i for i in range(self.config['num_sets'])]\n",
    "        client_slice = len(file_indices)//self.config['num_clients']\n",
    "        \n",
    "        self.loader = Dataloader(file_indices,[source*(client_slice),min((source+1)*(client_slice),35)])  \n",
    "        self.loader.load_training_dataset()\n",
    "        self.loader.load_testing_dataset()\n",
    "        \n",
    "        # Matrix to Record Performance (Old Metrics)\n",
    "        self.orig_acc_transfers = np.zeros((config['num_clients'],config['num_clients']))\n",
    "        self.orig_similarities = np.zeros((config['num_clients'],config['num_clients']))\n",
    "        self.orig_target_hit = np.zeros((config['num_clients'],config['num_clients']))\n",
    "        self.adv_acc_transfers = np.zeros((config['num_clients'],config['num_clients']))\n",
    "        self.adv_similarities = np.zeros((config['num_clients'],config['num_clients']))\n",
    "        self.adv_target_hit = np.zeros((config['num_clients'],config['num_clients']))\n",
    "        \n",
    "        # Matrix to Record Performance (New Metrics - theoretical)\n",
    "        \n",
    "        # Attack Params\n",
    "        self.ifsgm_params = IFSGM_Params()\n",
    "        self.cw_params = IFSGM_Params()\n",
    "        \n",
    "        \n",
    "        \n",
    "    def generate_victim(self, client_idx):\n",
    "        \"\"\"\n",
    "        Select specific client to load neural network to \n",
    "        Load the data for that client\n",
    "        Lod the weights for that client\n",
    "        \"\"\"\n",
    "        \n",
    "        \n",
    "        return\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transferer = Transferer(filename = 'exp2_neck2_head3')\n",
    "transferer.ifsgm_params.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Config File and Slie Indices\n",
    "with open(r'configs/config.yaml') as file:\n",
    "        config = yaml.load(file, Loader=yaml.FullLoader)\n",
    "        \n",
    "file_indices = [i for i in range(config['num_sets'])]\n",
    "#random.shuffle(file_indices)\n",
    "client_slice = len(file_indices)//config['num_clients']\n",
    "\n",
    "# File names of FL trained setting\n",
    "filenames = [\"exp2_neck2_head1\", \"exp2_neck2_head2\",\n",
    "             \"exp2_neck2_head3\", \"exp2_neck2_head4\"]\n",
    "\n",
    "# Matrix to Record Performance\n",
    "orig_acc_transfers = np.zeros((1,config['num_clients']))\n",
    "orig_similarities = np.zeros((1,config['num_clients']))\n",
    "orig_target_hit = np.zeros((1,config['num_clients']))\n",
    "adv_acc_transfers = np.zeros((1,config['num_clients']))\n",
    "adv_similarities = np.zeros((1,config['num_clients']))\n",
    "adv_target_hit = np.zeros((1,config['num_clients']))\n",
    "\n",
    "# Attack Params\n",
    "batch_size = 1000\n",
    "eps = 0.5\n",
    "alpha = 0.5\n",
    "iteration = 30\n",
    "target = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading  all_data_12_niid_0_keep_0_train_9.json\n",
      "Loading  all_data_20_niid_0_keep_0_train_9.json\n",
      "Loading  all_data_11_niid_0_keep_0_train_9.json\n",
      "Loading  all_data_18_niid_0_keep_0_train_9.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.8/site-packages/torch/nn/_reduction.py:43: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======== Source 0 ========\n",
      "    ==== Dest 0 ====\n",
      "---- Attack Transfer: ----\n",
      "\n",
      "         Orig Test Acc: 0.8980000615119934\n",
      "          Adv Test Acc: 0.07600000500679016\n",
      "Orig Output Similarity: 0.9830000400543213\n",
      " Adv Output Similarity: 0.1380000114440918\n",
      "       Orig Target Hit: 0.010000000707805157\n",
      "        Adv Target Hit: 0.04000000283122063\n",
      "    ==== Dest 1 ====\n",
      "---- Attack Transfer: ----\n",
      "\n",
      "         Orig Test Acc: 0.7950000166893005\n",
      "          Adv Test Acc: 0.06599999964237213\n",
      "Orig Output Similarity: 0.8540000319480896\n",
      " Adv Output Similarity: 0.08500000089406967\n",
      "       Orig Target Hit: 0.00800000037997961\n",
      "        Adv Target Hit: 0.018000001087784767\n",
      "    ==== Dest 2 ====\n",
      "---- Attack Transfer: ----\n",
      "\n",
      "         Orig Test Acc: 0.7720000147819519\n",
      "          Adv Test Acc: 0.08800000697374344\n",
      "Orig Output Similarity: 0.8170000314712524\n",
      " Adv Output Similarity: 0.09300000220537186\n",
      "       Orig Target Hit: 0.007000000216066837\n",
      "        Adv Target Hit: 0.018000001087784767\n",
      "    ==== Dest 3 ====\n",
      "---- Attack Transfer: ----\n",
      "\n",
      "         Orig Test Acc: 0.8370000123977661\n",
      "          Adv Test Acc: 0.08100000023841858\n",
      "Orig Output Similarity: 0.8730000257492065\n",
      " Adv Output Similarity: 0.09200000762939453\n",
      "       Orig Target Hit: 0.01100000087171793\n",
      "        Adv Target Hit: 0.03100000135600567\n",
      "    ==== Dest 4 ====\n",
      "---- Attack Transfer: ----\n",
      "\n",
      "         Orig Test Acc: 0.7190000414848328\n",
      "          Adv Test Acc: 0.07400000095367432\n",
      "Orig Output Similarity: 0.7700000405311584\n",
      " Adv Output Similarity: 0.08700000494718552\n",
      "       Orig Target Hit: 0.006000000052154064\n",
      "        Adv Target Hit: 0.014000000432133675\n",
      "    ==== Dest 5 ====\n",
      "---- Attack Transfer: ----\n",
      "\n",
      "         Orig Test Acc: 0.7750000357627869\n",
      "          Adv Test Acc: 0.07900000363588333\n",
      "Orig Output Similarity: 0.8200000524520874\n",
      " Adv Output Similarity: 0.08400000631809235\n",
      "       Orig Target Hit: 0.007000000216066837\n",
      "        Adv Target Hit: 0.014000000432133675\n",
      "    ==== Dest 6 ====\n",
      "---- Attack Transfer: ----\n",
      "\n",
      "         Orig Test Acc: 0.7950000166893005\n",
      "          Adv Test Acc: 0.07100000232458115\n",
      "Orig Output Similarity: 0.8460000157356262\n",
      " Adv Output Similarity: 0.07900000363588333\n",
      "       Orig Target Hit: 0.007000000216066837\n",
      "        Adv Target Hit: 0.012000000104308128\n",
      "    ==== Dest 7 ====\n",
      "---- Attack Transfer: ----\n",
      "\n",
      "         Orig Test Acc: 0.8190000653266907\n",
      "          Adv Test Acc: 0.07600000500679016\n",
      "Orig Output Similarity: 0.8640000224113464\n",
      " Adv Output Similarity: 0.10300000756978989\n",
      "       Orig Target Hit: 0.009000000543892384\n",
      "        Adv Target Hit: 0.02800000086426735\n"
     ]
    }
   ],
   "source": [
    "file = 'exp2_neck2_head3'\n",
    "\n",
    "for source in range(1):\n",
    "    \n",
    "    # Bring in the data loader for this client\n",
    "    loader = Dataloader(file_indices,[source*(client_slice),min((source+1)*(client_slice),35)])  \n",
    "    loader.load_training_dataset()\n",
    "    loader.load_testing_dataset()\n",
    "\n",
    "    victim_source = load_victim(source,loader,file)\n",
    "\n",
    "    # Generate adversarial Perturbations\n",
    "    victim_source.i_fgsm(batch_size = batch_size, target= target, eps=eps, alpha=alpha, \n",
    "               iteration=iteration, x_val_min=-1, x_val_max=1, print_info=False)\n",
    "\n",
    "    # Record relevant tensors\n",
    "    x_orig = victim_source.x_orig\n",
    "    y_orig = victim_source.output_orig\n",
    "    y_true = victim_source.y_orig\n",
    "    x_adv = victim_source.x_adv\n",
    "    y_adv = victim_source.output_adv\n",
    "\n",
    "    print(\"======== Source\", source, \"========\")\n",
    "\n",
    "    for dest in range(config['num_clients']):\n",
    "\n",
    "        print(\"    ==== Dest\", dest, \"====\")\n",
    "\n",
    "        victim_dest = load_victim(dest,loader,file)\n",
    "\n",
    "        # Compute Stats and record\n",
    "        victim_dest.forward_transfer(x_orig,x_adv,y_orig,y_adv,y_true, target, print_info=True)\n",
    "\n",
    "        orig_acc_transfers[source,dest] = victim_dest.orig_test_acc\n",
    "        orig_similarities[source,dest] = victim_dest.orig_output_sim\n",
    "        orig_target_hit[source,dest] = victim_dest.orig_target_achieve\n",
    "\n",
    "        adv_acc_transfers[source,dest] = victim_dest.adv_test_acc\n",
    "        adv_similarities[source,dest] = victim_dest.adv_output_sim\n",
    "        adv_target_hit[source,dest] = victim_dest.adv_target_achieve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "orig_acc_transfers\n",
      " [0.898 0.795 0.772 0.837 0.719 0.775 0.795 0.819]\n",
      "orig_similarities\n",
      " [[0.983 0.854 0.817 0.873 0.77  0.82  0.846 0.864]]\n",
      "orig_target_hit\n",
      " [[0.01  0.008 0.007 0.011 0.006 0.007 0.007 0.009]]\n",
      "adv_acc_transfers\n",
      " [[0.076 0.066 0.088 0.081 0.074 0.079 0.071 0.076]]\n",
      "adv_similarities\n",
      " [[0.138 0.085 0.093 0.092 0.087 0.084 0.079 0.103]]\n",
      "adv_target_hit\n",
      " [[0.04  0.018 0.018 0.031 0.014 0.014 0.012 0.028]]\n"
     ]
    }
   ],
   "source": [
    "print(\"orig_acc_transfers\\n\",np.round(orig_acc_transfers,3)[0])\n",
    "print(\"orig_similarities\\n\",np.round(orig_similarities,3))\n",
    "print(\"orig_target_hit\\n\",np.round(orig_target_hit,3))\n",
    "print(\"adv_acc_transfers\\n\",np.round(adv_acc_transfers,3))\n",
    "print(\"adv_similarities\\n\",np.round(adv_similarities,3))\n",
    "print(\"adv_target_hit\\n\",np.round(adv_target_hit,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
