{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FGSM Attack 1\n",
    "\n",
    "TJ Kim\n",
    "\n",
    "12.17.20\n",
    "\n",
    "### Summary:\n",
    "\n",
    "Load a single neural network within the multiple clients present in the federated learning setting. Then on that single neural network, make a Module.nn pytorch model with the weights and attack that.\n",
    "\n",
    "- Use misclassification attack first\n",
    "- Then move onto targetted attack\n",
    "\n",
    "\n",
    "The FGSM attack code is taken from here: https://pytorch.org/tutorials/beginner/fgsm_tutorial.html\n",
    "\n",
    "First move into working directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/satya_code\n"
     ]
    }
   ],
   "source": [
    "cd '/home/ubuntu/satya_code/' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Relevant Libraries and Modules\n",
    "\n",
    "Load the relevant libraries for the federated learning code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import yaml\n",
    "        \n",
    "from femnist_dataloader import Dataloader\n",
    "from cnn_head import CNN_Head\n",
    "from cnn_neck import CNN_Neck\n",
    "from cnn_server import Server\n",
    "from cnn_client import Client\n",
    "from data_manager import DataManager\n",
    "\n",
    "from utilities import freeze_layers\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import csv\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "import multiprocessing as mp\n",
    "\n",
    "import queue\n",
    "\n",
    "# Extra not from py file\n",
    "from collections import OrderedDict \n",
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the relevant libraries for example FGSM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Victim Model from FL Client\n",
    "\n",
    "Import the existing FL client weights, and attempt to reconstruct the architecture and load the relevant weights.\n",
    "\n",
    "First we build a custom nn module to hold the head and neck together. We desire to obtain gradient information from this victim model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Victim_NN(nn.Module):\n",
    "    \"\"\"\n",
    "    Summary: \n",
    "    \n",
    "    Pytorch NN module that takes pre-trained weights from layered personalized model\n",
    "    We also load the data-loader and give test,attack functionality\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, head_network, neck_network, dataloader):\n",
    "        \n",
    "        super(Victim_NN, self).__init__()\n",
    "        self.head = head_network\n",
    "        self.neck = neck_network\n",
    "        self.dataloader = dataloader\n",
    "        self.criterion = nn.NLLLoss()\n",
    "        \n",
    "        \n",
    "        # test_acc attributes\n",
    "        self.test_input = None\n",
    "        self.test_target = None\n",
    "        self.test_output = None\n",
    "        self.test_softmax = None\n",
    "        self.test_acc = None\n",
    "        self.test_loss = None\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.neck.forward(x)\n",
    "        x = self.head.forward(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    def forward_batch_test(self, batch_size, print_info = True):\n",
    "        \n",
    "        # Randomly select batch size and perform forward pass on specified data         \n",
    "        image_data = self.dataloader.load_batch(batch_size)\n",
    "        self.test_input  = torch.Tensor(image_data['input']).reshape(batch_size,1,28,28)\n",
    "        self.test_target  = torch.Tensor(image_data['label']).type(torch.LongTensor).cuda()\n",
    "        self.test_softmax = self.forward(self.test_input)\n",
    "        self.test_output = torch.argmax(self.test_softmax,dim = 1)\n",
    "        \n",
    "        # Record accuracy and loss\n",
    "        self.test_loss = self.criterion(self.test_softmax, self.test_target).item()\n",
    "        self.test_acc = (self.test_output == self.test_target).float().sum()/batch_size\n",
    "        \n",
    "        # Print Relevant Information\n",
    "        if print_info:\n",
    "            print(\"---- Test Batch Size:\", batch_size, \"----\")\n",
    "            print(\"Test Output:\", self.test_output.tolist())\n",
    "            print(\"Test Target:\", self.test_target.tolist())\n",
    "            print(\"Loss       :\", self.test_loss)\n",
    "            print(\"Test Acc   :\", self.test_acc.item())\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the first (0th) client weights into a dummy head/neck networks. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate Head and Neck NN objects\n",
    "mode = 'cuda'\n",
    "head_nn = CNN_Head(mode)\n",
    "neck_nn = CNN_Neck(mode)\n",
    "\n",
    "# Which network to load and directory\n",
    "i = 0\n",
    "exp_path = \"Results/federated_system/individual_head_networks/\"\n",
    "nn_path = exp_path + \"individual_head_networks_\"\n",
    "\n",
    "# Load pre-trained weights\n",
    "head_path = nn_path + str(i) +\"_head_network\"\n",
    "neck_path = nn_path + str(i) +\"_neck_network\"\n",
    "\n",
    "head = torch.load(head_path)\n",
    "neck = torch.load(neck_path)\n",
    "    \n",
    "head_edit = OrderedDict()\n",
    "neck_edit = OrderedDict()\n",
    "\n",
    "# Edit the ordered_dict key names to be torch compatible\n",
    "for key in head.keys():\n",
    "    head_edit[\"network.\"+key] = head[key]\n",
    "\n",
    "for key in neck.keys():\n",
    "    neck_edit[\"network.\"+key] = neck[key]\n",
    "\n",
    "head_nn.load_state_dict(head_edit)\n",
    "neck_nn.load_state_dict(neck_edit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction from Data Loader\n",
    "\n",
    "Pass inputs from the dataloader and see accuracy for this client."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading  all_data_12_niid_0_keep_0_train_9.json\n",
      "Loading  all_data_20_niid_0_keep_0_train_9.json\n",
      "Loading  all_data_11_niid_0_keep_0_train_9.json\n",
      "Loading  all_data_18_niid_0_keep_0_train_9.json\n"
     ]
    }
   ],
   "source": [
    "# Obtain Information Regarding Dataset Slices\n",
    "with open(r'config.yaml') as file:\n",
    "        config = yaml.load(file, Loader=yaml.FullLoader)\n",
    "        \n",
    "file_indices = [i for i in range(config['num_sets'])]\n",
    "#random.shuffle(file_indices)\n",
    "client_slice = len(file_indices)//config['num_clients']\n",
    "\n",
    "# Load the relevant dataloader for this specific user (0)\n",
    "i = 0\n",
    "loader = Dataloader(file_indices,[i*(client_slice),min((i+1)*(client_slice),35)])  \n",
    "loader.load_training_dataset()\n",
    "loader.load_testing_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "victim_nn = Victim_NN(head_nn,neck_nn,loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- Test Batch Size: 10 ----\n",
      "Test Output: [9, 24, 2, 5, 0, 19, 34, 40, 29, 0]\n",
      "Test Target: [9, 24, 2, 5, 0, 19, 53, 40, 29, 24]\n",
      "Loss       : 0.4579434394836426\n",
      "Test Acc   : 0.800000011920929\n"
     ]
    }
   ],
   "source": [
    "victim_nn.forward_batch_test(batch_size=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
