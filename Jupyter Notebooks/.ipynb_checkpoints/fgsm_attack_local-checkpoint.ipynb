{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FGSM Attack 1\n",
    "\n",
    "TJ Kim\n",
    "\n",
    "12.17.20\n",
    "\n",
    "### Summary:\n",
    "\n",
    "Load a single neural network within the multiple clients present in the federated learning setting. Then on that single neural network, make a Module.nn pytorch model with the weights and attack that.\n",
    "\n",
    "- Use misclassification attack first\n",
    "- Then move onto targetted attack\n",
    "\n",
    "\n",
    "The FGSM attack code is taken from here: https://pytorch.org/tutorials/beginner/fgsm_tutorial.html\n",
    "\n",
    "First move into working directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/satya_code\n"
     ]
    }
   ],
   "source": [
    "cd '/home/ubuntu/satya_code/' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Relevant Libraries and Modules\n",
    "\n",
    "Load the relevant libraries for the federated learning code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import yaml\n",
    "        \n",
    "from femnist_dataloader import Dataloader\n",
    "from cnn_head import CNN_Head\n",
    "from cnn_neck import CNN_Neck\n",
    "from cnn_server import Server\n",
    "from cnn_client import Client\n",
    "from data_manager import DataManager\n",
    "from utils import cuda, where\n",
    "\n",
    "from utilities import freeze_layers\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import csv\n",
    "import os\n",
    "import pickle\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import multiprocessing as mp\n",
    "\n",
    "import queue\n",
    "\n",
    "# Extra not from py file\n",
    "from collections import OrderedDict \n",
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the relevant libraries for example FGSM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Victim Model from FL Client\n",
    "\n",
    "Import the existing FL client weights, and attempt to reconstruct the architecture and load the relevant weights.\n",
    "\n",
    "First we build a custom nn module to hold the head and neck together. We desire to obtain gradient information from this victim model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Victim_NN(nn.Module):\n",
    "    \"\"\"\n",
    "    Summary: \n",
    "    \n",
    "    Pytorch NN module that takes pre-trained weights from layered personalized model\n",
    "    We also load the data-loader and give test,attack functionality\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, head_network, neck_network, dataloader):\n",
    "        \n",
    "        # Init attributes\n",
    "        super(Victim_NN, self).__init__()\n",
    "        self.head = head_network\n",
    "        self.neck = neck_network\n",
    "        self.dataloader = dataloader\n",
    "        self.criterion = nn.NLLLoss()\n",
    "        \n",
    "        # test_acc attributes\n",
    "        self.orig_test_acc = None\n",
    "        self.adv_test_acc = None\n",
    "        \n",
    "        self.orig_output_sim = None\n",
    "        self.adv_output_sim = None\n",
    "        \n",
    "        # I_FGSM attributes\n",
    "        self.x_orig = None\n",
    "        self.x_adv = None\n",
    "        self.y_orig = None\n",
    "        self.target = None\n",
    "        \n",
    "        self.softmax_orig = None\n",
    "        self.output_orig = None\n",
    "        self.softmax_adv = None\n",
    "        self.output_adv = None\n",
    "        \n",
    "        self.orig_loss = None\n",
    "        self.adv_loss = None\n",
    "        self.orig_acc = None\n",
    "        self.adv_acc = None\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.neck.forward(x)\n",
    "        x = self.head.forward(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    def forward_transfer(self, x_orig, x_adv, y_orig, y_adv,\n",
    "                         true_labels, target, print_info = False):\n",
    "        \"\"\"\n",
    "        Assume that input images are in pytorch tensor format\n",
    "        \"\"\"\n",
    "        \n",
    "        batch_size = y_orig.shape[0]\n",
    "        \n",
    "        # Forward Two Input Types\n",
    "        h_adv = self.forward(x_adv)\n",
    "        h_orig = self.forward(x_orig)\n",
    "        h_adv_category = torch.argmax(h_adv,dim = 1)\n",
    "        h_orig_category = torch.argmax(h_orig,dim = 1)\n",
    "        \n",
    "        # Record Different Parameters\n",
    "        self.orig_test_acc = (h_orig_category == true_labels).float().sum()/batch_size\n",
    "        self.adv_test_acc = (h_adv_category == true_labels).float().sum()/batch_size\n",
    "        \n",
    "        self.orig_output_sim = (h_orig_category == y_orig).float().sum()/batch_size\n",
    "        self.adv_output_sim = (h_adv_category == y_adv).float().sum()/batch_size\n",
    "        \n",
    "        self.orig_target_achieve = (h_orig_category == target).float().sum()/batch_size\n",
    "        self.adv_target_achieve = (h_adv_category == target).float().sum()/batch_size\n",
    "\n",
    "        \n",
    "        # Print Relevant Information\n",
    "        if print_info:\n",
    "            print(\"---- Attack Transfer:\", \"----\\n\")\n",
    "            print(\"         Orig Test Acc:\", self.orig_test_acc.item())\n",
    "            print(\"          Adv Test Acc:\", self.adv_test_acc.item())\n",
    "            print(\"Orig Output Similarity:\", self.orig_output_sim.item())\n",
    "            print(\" Adv Output Similarity:\", self.adv_output_sim.item())\n",
    "            print(\"       Orig Target Hit:\", self.orig_target_achieve.item())\n",
    "            print(\"        Adv Target Hit:\", self.adv_target_achieve.item())\n",
    "        \n",
    "    def i_fgsm(self, batch_size = 10, target= -1, eps=0.03, alpha=1, \n",
    "               iteration=1, x_val_min=-1, x_val_max=1, print_info=False):\n",
    "        \"\"\"\n",
    "        batch_size - number of images to adversarially perturb\n",
    "        targetted - target class output we desire to alter all inputs into\n",
    "        eps - max amount to add perturbations per pixel per iteration\n",
    "        alpha - gradient scaling (increase minimum perturbation amount below epsilon)\n",
    "        iteration - how many times to perturb\n",
    "        x_val_min/max - NN input valid range to keep perturbations within\n",
    "        \"\"\"\n",
    "        self.eval()\n",
    "        \n",
    "        # Load data to perturb\n",
    "    \n",
    "        image_data = self.dataloader.load_batch(batch_size)\n",
    "        self.x_orig  = torch.Tensor(image_data['input']).reshape(batch_size,1,28,28)\n",
    "        self.y_orig = torch.Tensor(image_data['label']).type(torch.LongTensor).cuda()\n",
    "        self.target = target\n",
    "        \n",
    "        self.x_adv = Variable(self.x_orig, requires_grad=True)\n",
    "        \n",
    "        for i in range(iteration):\n",
    "            \n",
    "            h_adv = self.forward(self.x_adv)\n",
    "            \n",
    "            # Loss function based on target\n",
    "            if target > -1:\n",
    "                target_tensor = torch.LongTensor(self.y_orig.size()).fill_(target)\n",
    "                target_tensor = Variable(cuda(target_tensor, self.cuda), requires_grad=False)\n",
    "                cost = self.criterion(h_adv, target_tensor)\n",
    "            else:\n",
    "                cost = -self.criterion(h_adv, self.y_orig)\n",
    "\n",
    "            self.zero_grad()\n",
    "\n",
    "            if self.x_adv.grad is not None:\n",
    "                self.x_adv.grad.data.fill_(0)\n",
    "            cost.backward()\n",
    "\n",
    "            self.x_adv.grad.sign_()\n",
    "            self.x_adv = self.x_adv - alpha*self.x_adv.grad\n",
    "            self.x_adv = where(self.x_adv > self.x_orig+eps, self.x_orig+eps, self.x_adv)\n",
    "            self.x_adv = where(self.x_adv < self.x_orig-eps, self.x_orig-eps, self.x_adv)\n",
    "            self.x_adv = torch.clamp(self.x_adv, x_val_min, x_val_max)\n",
    "            self.x_adv = Variable(self.x_adv.data, requires_grad=True)\n",
    "\n",
    "        self.softmax_orig = self.forward(self.x_orig)\n",
    "        self.output_orig = torch.argmax(self.softmax_orig,dim=1)\n",
    "        self.softmax_adv = self.forward(self.x_adv)\n",
    "        self.output_adv = torch.argmax(self.softmax_adv,dim=1)\n",
    "        \n",
    "        # Record accuracy and loss\n",
    "        self.orig_loss = self.criterion(self.softmax_orig, self.y_orig).item()\n",
    "        self.adv_loss = self.criterion(self.softmax_adv, self.y_orig).item()\n",
    "        self.orig_acc = (self.output_orig == self.y_orig).float().sum()/batch_size\n",
    "        self.adv_acc = (self.output_adv == self.y_orig).float().sum()/batch_size\n",
    "        \n",
    "        # Add Perturbation Distance (L2 norm) - across each input\n",
    "        self.norm = torch.norm(torch.sub(self.x_orig, self.x_adv, alpha=1),dim=(2,3))\n",
    "\n",
    "        # Print Relevant Information\n",
    "        if print_info:\n",
    "            print(\"---- FGSM Batch Size:\", batch_size, \"----\\n\")\n",
    "            print(\"Orig Target:\", self.y_orig.tolist())\n",
    "            print(\"Orig Output:\", self.output_orig.tolist())\n",
    "            print(\"ADV Output :\", self.output_adv.tolist(),'\\n')\n",
    "            print(\"Orig Loss  :\", self.orig_loss)\n",
    "            print(\"ADV Loss   :\", self.adv_loss,'\\n')\n",
    "            print(\"Orig Acc   :\", self.orig_acc.item())\n",
    "            print(\"ADV Acc    :\", self.adv_acc.item())\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the first (0th) client weights into a dummy head/neck networks. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.8/site-packages/torch/nn/_reduction.py:43: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate Head and Neck NN objects\n",
    "mode = 'cuda'\n",
    "head_nn = CNN_Head(mode)\n",
    "neck_nn = CNN_Neck(mode)\n",
    "\n",
    "# Which network to load and directory\n",
    "i = 0\n",
    "exp_path = \"Results/federated_system/individual_head_networks/\"\n",
    "nn_path = exp_path + \"individual_head_networks_\"\n",
    "\n",
    "# Load pre-trained weights\n",
    "head_path = nn_path + str(i) +\"_head_network\"\n",
    "neck_path = nn_path + str(i) +\"_neck_network\"\n",
    "\n",
    "head = torch.load(head_path)\n",
    "neck = torch.load(neck_path)\n",
    "    \n",
    "head_edit = OrderedDict()\n",
    "neck_edit = OrderedDict()\n",
    "\n",
    "# Edit the ordered_dict key names to be torch compatible\n",
    "for key in head.keys():\n",
    "    head_edit[\"network.\"+key] = head[key]\n",
    "\n",
    "for key in neck.keys():\n",
    "    neck_edit[\"network.\"+key] = neck[key]\n",
    "\n",
    "head_nn.load_state_dict(head_edit)\n",
    "neck_nn.load_state_dict(neck_edit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loader and IFGSM Attack\n",
    "\n",
    "Pass inputs from the dataloader and see accuracy for this client."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading  all_data_12_niid_0_keep_0_train_9.json\n",
      "Loading  all_data_20_niid_0_keep_0_train_9.json\n",
      "Loading  all_data_11_niid_0_keep_0_train_9.json\n",
      "Loading  all_data_18_niid_0_keep_0_train_9.json\n"
     ]
    }
   ],
   "source": [
    "# Obtain Information Regarding Dataset Slices\n",
    "with open(r'config.yaml') as file:\n",
    "        config = yaml.load(file, Loader=yaml.FullLoader)\n",
    "        \n",
    "file_indices = [i for i in range(config['num_sets'])]\n",
    "#random.shuffle(file_indices)\n",
    "client_slice = len(file_indices)//config['num_clients']\n",
    "\n",
    "# Load the relevant dataloader for this specific user (0)\n",
    "i = 0\n",
    "loader = Dataloader(file_indices,[i*(client_slice),min((i+1)*(client_slice),35)])  \n",
    "loader.load_training_dataset()\n",
    "loader.load_testing_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "victim_nn = Victim_NN(head_nn,neck_nn,loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- FGSM Batch Size: 20 ----\n",
      "\n",
      "Orig Target: [8, 3, 1, 28, 24, 34, 0, 31, 36, 40, 7, 44, 8, 24, 47, 27, 6, 22, 36, 2]\n",
      "Orig Output: [8, 3, 1, 28, 24, 34, 0, 31, 36, 40, 7, 44, 8, 0, 47, 27, 6, 22, 36, 2]\n",
      "ADV Output : [8, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 55, 5, 5, 5, 10, 5] \n",
      "\n",
      "Orig Loss  : 0.1797807663679123\n",
      "ADV Loss   : 6.2781171798706055 \n",
      "\n",
      "Orig Acc   : 0.949999988079071\n",
      "ADV Acc    : 0.05000000074505806\n"
     ]
    }
   ],
   "source": [
    "victim_nn.i_fgsm(batch_size = 20, target= 5, eps=0.1, alpha=0.1, \n",
    "               iteration=30, x_val_min=-1, x_val_max=1, print_info=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- Attack Transfer: ----\n",
      "\n",
      "         Orig Test Acc: 0.949999988079071\n",
      "          Adv Test Acc: 0.05000000074505806\n",
      "Orig Output Similarity: 1.0\n",
      " Adv Output Similarity: 1.0\n",
      "       Orig Target Hit: 0.0\n",
      "        Adv Target Hit: 0.8500000238418579\n"
     ]
    }
   ],
   "source": [
    "victim_nn.forward_transfer(victim_nn.x_orig, victim_nn.x_adv, victim_nn.output_orig, victim_nn.output_adv,\n",
    "                         victim_nn.y_orig, victim_nn.target, print_info = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transfer Attack Between All 8 Clients\n",
    "\n",
    "Load all data loaders and perform transfer attacks amongst each of the clients in the system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matrix to Record Performance\n",
    "orig_acc_transfers = np.zeros((config['num_clients'],config['num_clients']))\n",
    "orig_similarities = np.zeros((config['num_clients'],config['num_clients']))\n",
    "orig_target_hit = np.zeros((config['num_clients'],config['num_clients']))\n",
    "adv_acc_transfers = np.zeros((config['num_clients'],config['num_clients']))\n",
    "adv_similarities = np.zeros((config['num_clients'],config['num_clients']))\n",
    "adv_target_hit = np.zeros((config['num_clients'],config['num_clients']))\n",
    "\n",
    "\n",
    "# Attack Params\n",
    "batch_size = 1000\n",
    "eps = 0.1\n",
    "alpha = 0.1\n",
    "iteration = 20\n",
    "target = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_victim(idx, loader):\n",
    "    # Load the corresponding head/neck network in victim nn module \n",
    "    \n",
    "    # Which network to load and directory\n",
    "    exp_path = \"Results/federated_system/individual_head_networks/\"\n",
    "    nn_path = exp_path + \"individual_head_networks_\"\n",
    "\n",
    "    # Load pre-trained weights\n",
    "    head_path = nn_path + str(idx) +\"_head_network\"\n",
    "    neck_path = nn_path + str(idx) +\"_neck_network\"\n",
    "\n",
    "    head = torch.load(head_path)\n",
    "    neck = torch.load(neck_path)\n",
    "\n",
    "    head_edit = OrderedDict()\n",
    "    neck_edit = OrderedDict()\n",
    "\n",
    "    # Edit the ordered_dict key names to be torch compatible\n",
    "    for key in head.keys():\n",
    "        head_edit[\"network.\"+key] = head[key]\n",
    "\n",
    "    for key in neck.keys():\n",
    "        neck_edit[\"network.\"+key] = neck[key]\n",
    "\n",
    "    head_nn.load_state_dict(head_edit)\n",
    "    neck_nn.load_state_dict(neck_edit)\n",
    "    \n",
    "    return Victim_NN(head_nn,neck_nn,loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading  all_data_12_niid_0_keep_0_train_9.json\n",
      "Loading  all_data_20_niid_0_keep_0_train_9.json\n",
      "Loading  all_data_11_niid_0_keep_0_train_9.json\n",
      "Loading  all_data_18_niid_0_keep_0_train_9.json\n",
      "======== Source 0 ========\n",
      "    ==== Dest 0 ====\n",
      "    ==== Dest 0 ====\n",
      "    ==== Dest 0 ====\n",
      "    ==== Dest 0 ====\n",
      "    ==== Dest 0 ====\n",
      "    ==== Dest 0 ====\n",
      "    ==== Dest 0 ====\n",
      "    ==== Dest 0 ====\n",
      "Loading  all_data_0_niid_0_keep_0_train_9.json\n",
      "Loading  all_data_34_niid_0_keep_0_train_9.json\n",
      "Loading  all_data_17_niid_0_keep_0_train_9.json\n",
      "Loading  all_data_13_niid_0_keep_0_train_9.json\n",
      "======== Source 1 ========\n",
      "    ==== Dest 1 ====\n",
      "    ==== Dest 1 ====\n",
      "    ==== Dest 1 ====\n",
      "    ==== Dest 1 ====\n",
      "    ==== Dest 1 ====\n",
      "    ==== Dest 1 ====\n",
      "    ==== Dest 1 ====\n",
      "    ==== Dest 1 ====\n",
      "Loading  all_data_7_niid_0_keep_0_train_9.json\n",
      "Loading  all_data_33_niid_0_keep_0_train_9.json\n",
      "Loading  all_data_24_niid_0_keep_0_train_9.json\n",
      "Loading  all_data_5_niid_0_keep_0_train_9.json\n",
      "======== Source 2 ========\n",
      "    ==== Dest 2 ====\n",
      "    ==== Dest 2 ====\n",
      "    ==== Dest 2 ====\n",
      "    ==== Dest 2 ====\n",
      "    ==== Dest 2 ====\n",
      "    ==== Dest 2 ====\n",
      "    ==== Dest 2 ====\n",
      "    ==== Dest 2 ====\n",
      "Loading  all_data_27_niid_0_keep_0_train_9.json\n",
      "Loading  all_data_26_niid_0_keep_0_train_9.json\n",
      "Loading  all_data_21_niid_0_keep_0_train_9.json\n",
      "Loading  all_data_10_niid_0_keep_0_train_9.json\n",
      "======== Source 3 ========\n",
      "    ==== Dest 3 ====\n",
      "    ==== Dest 3 ====\n",
      "    ==== Dest 3 ====\n",
      "    ==== Dest 3 ====\n",
      "    ==== Dest 3 ====\n",
      "    ==== Dest 3 ====\n",
      "    ==== Dest 3 ====\n",
      "    ==== Dest 3 ====\n",
      "Loading  all_data_19_niid_0_keep_0_train_9.json\n",
      "Loading  all_data_6_niid_0_keep_0_train_9.json\n",
      "Loading  all_data_32_niid_0_keep_0_train_9.json\n",
      "Loading  all_data_15_niid_0_keep_0_train_9.json\n",
      "======== Source 4 ========\n",
      "    ==== Dest 4 ====\n",
      "    ==== Dest 4 ====\n",
      "    ==== Dest 4 ====\n",
      "    ==== Dest 4 ====\n",
      "    ==== Dest 4 ====\n",
      "    ==== Dest 4 ====\n",
      "    ==== Dest 4 ====\n",
      "    ==== Dest 4 ====\n",
      "Loading  all_data_2_niid_0_keep_0_train_9.json\n",
      "Loading  all_data_3_niid_0_keep_0_train_9.json\n",
      "Loading  all_data_31_niid_0_keep_0_train_9.json\n",
      "Loading  all_data_30_niid_0_keep_0_train_9.json\n",
      "======== Source 5 ========\n",
      "    ==== Dest 5 ====\n",
      "    ==== Dest 5 ====\n",
      "    ==== Dest 5 ====\n",
      "    ==== Dest 5 ====\n",
      "    ==== Dest 5 ====\n",
      "    ==== Dest 5 ====\n",
      "    ==== Dest 5 ====\n",
      "    ==== Dest 5 ====\n",
      "Loading  all_data_16_niid_0_keep_0_train_9.json\n",
      "Loading  all_data_8_niid_0_keep_0_train_9.json\n",
      "Loading  all_data_25_niid_0_keep_0_train_9.json\n",
      "Loading  all_data_1_niid_0_keep_0_train_9.json\n",
      "======== Source 6 ========\n",
      "    ==== Dest 6 ====\n",
      "    ==== Dest 6 ====\n",
      "    ==== Dest 6 ====\n",
      "    ==== Dest 6 ====\n",
      "    ==== Dest 6 ====\n",
      "    ==== Dest 6 ====\n",
      "    ==== Dest 6 ====\n",
      "    ==== Dest 6 ====\n",
      "Loading  all_data_14_niid_0_keep_0_train_9.json\n",
      "Loading  all_data_28_niid_0_keep_0_train_9.json\n",
      "Loading  all_data_9_niid_0_keep_0_train_9.json\n",
      "Loading  all_data_22_niid_0_keep_0_train_9.json\n",
      "======== Source 7 ========\n",
      "    ==== Dest 7 ====\n",
      "    ==== Dest 7 ====\n",
      "    ==== Dest 7 ====\n",
      "    ==== Dest 7 ====\n",
      "    ==== Dest 7 ====\n",
      "    ==== Dest 7 ====\n",
      "    ==== Dest 7 ====\n",
      "    ==== Dest 7 ====\n"
     ]
    }
   ],
   "source": [
    "for source in range(config['num_clients']):\n",
    "    \n",
    "    # Bring in the data loader for this client\n",
    "    loader = Dataloader(file_indices,[source*(client_slice),min((source+1)*(client_slice),35)])  \n",
    "    loader.load_training_dataset()\n",
    "    loader.load_testing_dataset()\n",
    "    \n",
    "    victim_source = load_victim(source,loader)\n",
    "    \n",
    "    # Generate adversarial Perturbations\n",
    "    victim_source.i_fgsm(batch_size = batch_size, target= target, eps=eps, alpha=alpha, \n",
    "               iteration=iteration, x_val_min=-1, x_val_max=1, print_info=False)\n",
    "    \n",
    "    # Record relevant tensors\n",
    "    x_orig = victim_source.x_orig\n",
    "    y_orig = victim_source.output_orig\n",
    "    y_true = victim_source.y_orig\n",
    "    x_adv = victim_source.x_adv\n",
    "    y_adv = victim_source.output_adv\n",
    "    \n",
    "    print(\"======== Source\", source, \"========\")\n",
    "    \n",
    "    for dest in range(config['num_clients']):\n",
    "        \n",
    "        print(\"    ==== Dest\", dest, \"====\")\n",
    "        \n",
    "        victim_dest = load_victim(dest,loader)\n",
    "            \n",
    "        # Compute Stats and record\n",
    "        victim_dest.forward_transfer(x_orig,x_adv,y_orig,y_adv,y_true, target, print_info=False)\n",
    "        \n",
    "        orig_acc_transfers[source,dest] = victim_dest.orig_test_acc\n",
    "        orig_similarities[source,dest] = victim_dest.orig_output_sim\n",
    "        orig_target_hit[source,dest] = victim_dest.orig_target_achieve\n",
    "        \n",
    "        adv_acc_transfers[source,dest] = victim_dest.adv_test_acc\n",
    "        adv_similarities[source,dest] = victim_dest.adv_output_sim\n",
    "        adv_target_hit[source,dest] = victim_dest.adv_target_achieve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "orig_acc_transfers\n",
      " [[0.908 0.827 0.81  0.867 0.763 0.825 0.81  0.866]\n",
      " [0.799 0.799 0.824 0.774 0.783 0.824 0.819 0.826]\n",
      " [0.72  0.798 0.798 0.656 0.783 0.8   0.8   0.789]\n",
      " [0.839 0.771 0.735 0.735 0.619 0.732 0.718 0.824]\n",
      " [0.758 0.81  0.81  0.708 0.708 0.811 0.824 0.785]\n",
      " [0.753 0.824 0.812 0.692 0.795 0.795 0.829 0.787]\n",
      " [0.777 0.81  0.818 0.744 0.792 0.821 0.821 0.806]\n",
      " [0.776 0.757 0.766 0.767 0.672 0.755 0.741 0.741]]\n",
      "orig_similarities\n",
      " [[1.    0.849 0.845 0.895 0.797 0.85  0.838 0.904]\n",
      " [0.838 0.838 0.873 0.789 0.824 0.859 0.857 0.853]\n",
      " [0.76  0.86  0.86  0.682 0.831 0.856 0.855 0.839]\n",
      " [0.868 0.803 0.76  0.76  0.637 0.766 0.744 0.869]\n",
      " [0.797 0.862 0.875 0.733 0.733 0.88  0.889 0.826]\n",
      " [0.763 0.874 0.867 0.691 0.851 0.851 0.878 0.808]\n",
      " [0.792 0.863 0.871 0.762 0.855 0.866 0.866 0.845]\n",
      " [0.834 0.795 0.806 0.819 0.695 0.795 0.782 0.782]]\n",
      "orig_target_hit\n",
      " [[0.053 0.053 0.057 0.046 0.055 0.053 0.051 0.05 ]\n",
      " [0.051 0.051 0.061 0.048 0.062 0.056 0.058 0.052]\n",
      " [0.047 0.066 0.066 0.045 0.069 0.064 0.068 0.061]\n",
      " [0.042 0.044 0.05  0.05  0.057 0.044 0.05  0.041]\n",
      " [0.051 0.058 0.056 0.048 0.048 0.06  0.06  0.053]\n",
      " [0.044 0.052 0.051 0.038 0.059 0.059 0.05  0.048]\n",
      " [0.04  0.047 0.052 0.041 0.052 0.046 0.046 0.045]\n",
      " [0.032 0.041 0.042 0.034 0.05  0.036 0.043 0.043]]\n",
      "adv_acc_transfers\n",
      " [[0.141 0.278 0.316 0.49  0.249 0.311 0.313 0.327]\n",
      " [0.281 0.281 0.35  0.467 0.348 0.362 0.32  0.345]\n",
      " [0.273 0.331 0.331 0.392 0.305 0.318 0.297 0.314]\n",
      " [0.249 0.252 0.294 0.294 0.234 0.289 0.24  0.34 ]\n",
      " [0.308 0.407 0.369 0.449 0.449 0.397 0.337 0.335]\n",
      " [0.276 0.345 0.317 0.376 0.318 0.318 0.278 0.305]\n",
      " [0.282 0.309 0.299 0.404 0.302 0.308 0.308 0.293]\n",
      " [0.274 0.309 0.311 0.466 0.276 0.318 0.284 0.284]]\n",
      "adv_similarities\n",
      " [[1.    0.683 0.574 0.29  0.606 0.601 0.54  0.554]\n",
      " [0.693 0.693 0.629 0.357 0.669 0.646 0.627 0.563]\n",
      " [0.598 0.616 0.616 0.255 0.682 0.658 0.68  0.579]\n",
      " [0.589 0.589 0.575 0.575 0.526 0.584 0.556 0.596]\n",
      " [0.589 0.637 0.625 0.267 0.267 0.581 0.632 0.556]\n",
      " [0.605 0.621 0.684 0.274 0.641 0.641 0.695 0.566]\n",
      " [0.58  0.625 0.636 0.273 0.637 0.614 0.614 0.571]\n",
      " [0.651 0.61  0.602 0.334 0.582 0.585 0.599 0.599]]\n",
      "adv_target_hit\n",
      " [[0.826 0.594 0.474 0.18  0.528 0.509 0.458 0.459]\n",
      " [0.578 0.578 0.485 0.184 0.525 0.491 0.51  0.433]\n",
      " [0.508 0.504 0.504 0.144 0.565 0.535 0.569 0.455]\n",
      " [0.621 0.548 0.518 0.518 0.518 0.55  0.528 0.437]\n",
      " [0.466 0.478 0.475 0.139 0.139 0.428 0.509 0.421]\n",
      " [0.503 0.503 0.548 0.156 0.514 0.514 0.573 0.443]\n",
      " [0.472 0.529 0.527 0.168 0.513 0.514 0.514 0.454]\n",
      " [0.551 0.501 0.504 0.153 0.505 0.488 0.497 0.497]]\n"
     ]
    }
   ],
   "source": [
    "print(\"orig_acc_transfers\\n\",np.round(orig_acc_transfers,3))\n",
    "print(\"orig_similarities\\n\",np.round(orig_similarities,3))\n",
    "print(\"orig_target_hit\\n\",np.round(orig_target_hit,3))\n",
    "print(\"adv_acc_transfers\\n\",np.round(adv_acc_transfers,3))\n",
    "print(\"adv_similarities\\n\",np.round(adv_similarities,3))\n",
    "print(\"adv_target_hit\\n\",np.round(adv_target_hit,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
