{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FGSM Attack 1\n",
    "\n",
    "TJ Kim\n",
    "\n",
    "12.17.20\n",
    "\n",
    "### Summary:\n",
    "\n",
    "Load a single neural network within the multiple clients present in the federated learning setting. Then on that single neural network, make a Module.nn pytorch model with the weights and attack that.\n",
    "\n",
    "- Use misclassification attack first\n",
    "- Then move onto targetted attack\n",
    "\n",
    "\n",
    "The FGSM attack code is taken from here: https://pytorch.org/tutorials/beginner/fgsm_tutorial.html\n",
    "\n",
    "First move into working directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/satya_code\n"
     ]
    }
   ],
   "source": [
    "cd '/home/ubuntu/satya_code/' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Relevant Libraries and Modules\n",
    "\n",
    "Load the relevant libraries for the federated learning code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import yaml\n",
    "        \n",
    "from femnist_dataloader import Dataloader\n",
    "from cnn_head import CNN_Head\n",
    "from cnn_neck import CNN_Neck\n",
    "from cnn_server import Server\n",
    "from cnn_client import Client\n",
    "from data_manager import DataManager\n",
    "from utils import cuda, where\n",
    "\n",
    "from utilities import freeze_layers\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import csv\n",
    "import os\n",
    "import pickle\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import multiprocessing as mp\n",
    "\n",
    "import queue\n",
    "\n",
    "# Extra not from py file\n",
    "from collections import OrderedDict \n",
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the relevant libraries for example FGSM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Victim Model from FL Client\n",
    "\n",
    "Import the existing FL client weights, and attempt to reconstruct the architecture and load the relevant weights.\n",
    "\n",
    "First we build a custom nn module to hold the head and neck together. We desire to obtain gradient information from this victim model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Victim_NN(nn.Module):\n",
    "    \"\"\"\n",
    "    Summary: \n",
    "    \n",
    "    Pytorch NN module that takes pre-trained weights from layered personalized model\n",
    "    We also load the data-loader and give test,attack functionality\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, head_network, neck_network, dataloader):\n",
    "        \n",
    "        # Init attributes\n",
    "        super(Victim_NN, self).__init__()\n",
    "        self.head = head_network\n",
    "        self.neck = neck_network\n",
    "        self.dataloader = dataloader\n",
    "        self.criterion = nn.NLLLoss()\n",
    "        \n",
    "        # test_acc attributes\n",
    "        self.orig_test_acc = None\n",
    "        self.adv_test_acc = None\n",
    "        \n",
    "        self.orig_output_sim = None\n",
    "        self.adv_output_sim = None\n",
    "        \n",
    "        # I_FGSM attributes\n",
    "        self.x_orig = None\n",
    "        self.x_adv = None\n",
    "        self.y_orig = None\n",
    "        self.target = None\n",
    "        \n",
    "        self.softmax_orig = None\n",
    "        self.output_orig = None\n",
    "        self.softmax_adv = None\n",
    "        self.output_adv = None\n",
    "        \n",
    "        self.orig_loss = None\n",
    "        self.adv_loss = None\n",
    "        self.orig_acc = None\n",
    "        self.adv_acc = None\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.neck.forward(x)\n",
    "        x = self.head.forward(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    def forward_transfer(self, x_orig, x_adv, y_orig, y_adv,\n",
    "                         true_labels, target, print_info = False):\n",
    "        \"\"\"\n",
    "        Assume that input images are in pytorch tensor format\n",
    "        \"\"\"\n",
    "        \n",
    "        batch_size = y_orig.shape[0]\n",
    "        \n",
    "        # Forward Two Input Types\n",
    "        h_adv = self.forward(x_adv)\n",
    "        h_orig = self.forward(x_orig)\n",
    "        h_adv_category = torch.argmax(h_adv,dim = 1)\n",
    "        h_orig_category = torch.argmax(h_orig,dim = 1)\n",
    "        \n",
    "        # Record Different Parameters\n",
    "        self.orig_test_acc = (h_orig_category == true_labels).float().sum()/batch_size\n",
    "        self.adv_test_acc = (h_adv_category == true_labels).float().sum()/batch_size\n",
    "        \n",
    "        self.orig_output_sim = (h_orig_category == y_orig).float().sum()/batch_size\n",
    "        self.adv_output_sim = (h_adv_category == y_adv).float().sum()/batch_size\n",
    "        \n",
    "        self.orig_target_achieve = (h_orig_category == target).float().sum()/batch_size\n",
    "        self.adv_target_achieve = (h_adv_category == target).float().sum()/batch_size\n",
    "\n",
    "        \n",
    "        # Print Relevant Information\n",
    "        if print_info:\n",
    "            print(\"---- Attack Transfer:\", \"----\\n\")\n",
    "            print(\"         Orig Test Acc:\", self.orig_test_acc.item())\n",
    "            print(\"          Adv Test Acc:\", self.adv_test_acc.item())\n",
    "            print(\"Orig Output Similarity:\", self.orig_output_sim.item())\n",
    "            print(\" Adv Output Similarity:\", self.adv_output_sim.item())\n",
    "            print(\"       Orig Target Hit:\", self.orig_target_achieve.item())\n",
    "            print(\"        Adv Target Hit:\", self.adv_target_achieve.item())\n",
    "        \n",
    "    def i_fgsm(self, batch_size = 10, target= -1, eps=0.03, alpha=1, \n",
    "               iteration=1, x_val_min=-1, x_val_max=1, print_info=False):\n",
    "        \"\"\"\n",
    "        batch_size - number of images to adversarially perturb\n",
    "        targetted - target class output we desire to alter all inputs into\n",
    "        eps - max amount to add perturbations per pixel per iteration\n",
    "        alpha - gradient scaling (increase minimum perturbation amount below epsilon)\n",
    "        iteration - how many times to perturb\n",
    "        x_val_min/max - NN input valid range to keep perturbations within\n",
    "        \"\"\"\n",
    "        self.eval()\n",
    "        \n",
    "        # Load data to perturb\n",
    "    \n",
    "        image_data = self.dataloader.load_batch(batch_size)\n",
    "        self.x_orig  = torch.Tensor(image_data['input']).reshape(batch_size,1,28,28)\n",
    "        self.y_orig = torch.Tensor(image_data['label']).type(torch.LongTensor).cuda()\n",
    "        self.target = target\n",
    "        \n",
    "        self.x_adv = Variable(self.x_orig, requires_grad=True)\n",
    "        \n",
    "        for i in range(iteration):\n",
    "            \n",
    "            h_adv = self.forward(self.x_adv)\n",
    "            \n",
    "            # Loss function based on target\n",
    "            if target > -1:\n",
    "                target_tensor = torch.LongTensor(self.y_orig.size()).fill_(target)\n",
    "                target_tensor = Variable(cuda(target_tensor, self.cuda), requires_grad=False)\n",
    "                cost = self.criterion(h_adv, target_tensor)\n",
    "            else:\n",
    "                cost = -self.criterion(h_adv, self.y_orig)\n",
    "\n",
    "            self.zero_grad()\n",
    "\n",
    "            if self.x_adv.grad is not None:\n",
    "                self.x_adv.grad.data.fill_(0)\n",
    "            cost.backward()\n",
    "\n",
    "            self.x_adv.grad.sign_()\n",
    "            self.x_adv = self.x_adv - alpha*self.x_adv.grad\n",
    "            self.x_adv = where(self.x_adv > self.x_orig+eps, self.x_orig+eps, self.x_adv)\n",
    "            self.x_adv = where(self.x_adv < self.x_orig-eps, self.x_orig-eps, self.x_adv)\n",
    "            self.x_adv = torch.clamp(self.x_adv, x_val_min, x_val_max)\n",
    "            self.x_adv = Variable(self.x_adv.data, requires_grad=True)\n",
    "\n",
    "        self.softmax_orig = self.forward(self.x_orig)\n",
    "        self.output_orig = torch.argmax(self.softmax_orig,dim=1)\n",
    "        self.softmax_adv = self.forward(self.x_adv)\n",
    "        self.output_adv = torch.argmax(self.softmax_adv,dim=1)\n",
    "        \n",
    "        # Record accuracy and loss\n",
    "        self.orig_loss = self.criterion(self.softmax_orig, self.y_orig).item()\n",
    "        self.adv_loss = self.criterion(self.softmax_adv, self.y_orig).item()\n",
    "        self.orig_acc = (self.output_orig == self.y_orig).float().sum()/batch_size\n",
    "        self.adv_acc = (self.output_adv == self.y_orig).float().sum()/batch_size\n",
    "        \n",
    "        # Add Perturbation Distance (L2 norm) - across each input\n",
    "        self.norm = torch.norm(torch.sub(self.x_orig, self.x_adv, alpha=1),dim=(2,3))\n",
    "\n",
    "        # Print Relevant Information\n",
    "        if print_info:\n",
    "            print(\"---- FGSM Batch Size:\", batch_size, \"----\\n\")\n",
    "            print(\"Orig Target:\", self.y_orig.tolist())\n",
    "            print(\"Orig Output:\", self.output_orig.tolist())\n",
    "            print(\"ADV Output :\", self.output_adv.tolist(),'\\n')\n",
    "            print(\"Orig Loss  :\", self.orig_loss)\n",
    "            print(\"ADV Loss   :\", self.adv_loss,'\\n')\n",
    "            print(\"Orig Acc   :\", self.orig_acc.item())\n",
    "            print(\"ADV Acc    :\", self.adv_acc.item())\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the first (0th) client weights into a dummy head/neck networks. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.8/site-packages/torch/nn/_reduction.py:43: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate Head and Neck NN objects\n",
    "mode = 'cuda'\n",
    "head_nn = CNN_Head(mode)\n",
    "neck_nn = CNN_Neck(mode)\n",
    "\n",
    "# Which network to load and directory\n",
    "i = 0\n",
    "exp_path = \"Results/federated_system/individual_head_networks/\"\n",
    "nn_path = exp_path + \"individual_head_networks_\"\n",
    "\n",
    "# Load pre-trained weights\n",
    "head_path = nn_path + str(i) +\"_head_network\"\n",
    "neck_path = nn_path + str(i) +\"_neck_network\"\n",
    "\n",
    "head = torch.load(head_path)\n",
    "neck = torch.load(neck_path)\n",
    "    \n",
    "head_edit = OrderedDict()\n",
    "neck_edit = OrderedDict()\n",
    "\n",
    "# Edit the ordered_dict key names to be torch compatible\n",
    "for key in head.keys():\n",
    "    head_edit[\"network.\"+key] = head[key]\n",
    "\n",
    "for key in neck.keys():\n",
    "    neck_edit[\"network.\"+key] = neck[key]\n",
    "\n",
    "head_nn.load_state_dict(head_edit)\n",
    "neck_nn.load_state_dict(neck_edit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loader and IFGSM Attack\n",
    "\n",
    "Pass inputs from the dataloader and see accuracy for this client."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading  all_data_12_niid_0_keep_0_train_9.json\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-08f3d7461424>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataloader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_indices\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclient_slice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclient_slice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m35\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mloader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_training_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0mloader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_testing_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/satya_code/femnist_dataloader.py\u001b[0m in \u001b[0;36mload_training_dataset\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson_file_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m             \u001b[0mwriters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'users'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/json/__init__.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(fp, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    291\u001b[0m     \u001b[0mkwarg\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0motherwise\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mJSONDecoder\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mused\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m     \"\"\"\n\u001b[0;32m--> 293\u001b[0;31m     return loads(fp.read(),\n\u001b[0m\u001b[1;32m    294\u001b[0m         \u001b[0mcls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobject_hook\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobject_hook\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m         \u001b[0mparse_float\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparse_float\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparse_int\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparse_int\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/json/__init__.py\u001b[0m in \u001b[0;36mloads\u001b[0;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    355\u001b[0m             \u001b[0mparse_int\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mparse_float\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m             parse_constant is None and object_pairs_hook is None and not kw):\n\u001b[0;32m--> 357\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_default_decoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m         \u001b[0mcls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mJSONDecoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/json/decoder.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    335\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m         \"\"\"\n\u001b[0;32m--> 337\u001b[0;31m         \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    338\u001b[0m         \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/json/decoder.py\u001b[0m in \u001b[0;36mraw_decode\u001b[0;34m(self, s, idx)\u001b[0m\n\u001b[1;32m    351\u001b[0m         \"\"\"\n\u001b[1;32m    352\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 353\u001b[0;31m             \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscan_once\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    354\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mJSONDecodeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Expecting value\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Obtain Information Regarding Dataset Slices\n",
    "with open(r'config.yaml') as file:\n",
    "        config = yaml.load(file, Loader=yaml.FullLoader)\n",
    "        \n",
    "file_indices = [i for i in range(config['num_sets'])]\n",
    "#random.shuffle(file_indices)\n",
    "client_slice = len(file_indices)//config['num_clients']\n",
    "\n",
    "# Load the relevant dataloader for this specific user (0)\n",
    "i = 0\n",
    "loader = Dataloader(file_indices,[i*(client_slice),min((i+1)*(client_slice),35)])  \n",
    "loader.load_training_dataset()\n",
    "loader.load_testing_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "victim_nn = Victim_NN(head_nn,neck_nn,loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "victim_nn.i_fgsm(batch_size = 20, target= 5, eps=0.1, alpha=0.1, \n",
    "               iteration=30, x_val_min=-1, x_val_max=1, print_info=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "victim_nn.forward_transfer(victim_nn.x_orig, victim_nn.x_adv, victim_nn.output_orig, victim_nn.output_adv,\n",
    "                         victim_nn.y_orig, victim_nn.target, print_info = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transfer Attack Between All 8 Clients\n",
    "\n",
    "Load all data loaders and perform transfer attacks amongst each of the clients in the system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matrix to Record Performance\n",
    "orig_acc_transfers = np.zeros((1,config['num_clients']))\n",
    "orig_similarities = np.zeros((1,config['num_clients']))\n",
    "orig_target_hit = np.zeros((1,config['num_clients']))\n",
    "adv_acc_transfers = np.zeros((1,config['num_clients']))\n",
    "adv_similarities = np.zeros((1,config['num_clients']))\n",
    "adv_target_hit = np.zeros((1,config['num_clients']))\n",
    "\n",
    "\n",
    "# Attack Params\n",
    "batch_size = 1000\n",
    "eps = 0.1\n",
    "alpha = 0.1\n",
    "iteration = 20\n",
    "target = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_victim(idx, loader):\n",
    "    # Load the corresponding head/neck network in victim nn module \n",
    "    \n",
    "    # Which network to load and directory\n",
    "    exp_path = \"Results/federated_system/individual_head_networks/\"\n",
    "    nn_path = exp_path + \"individual_head_networks_\"\n",
    "\n",
    "    # Load pre-trained weights\n",
    "    head_path = nn_path + str(idx) +\"_head_network\"\n",
    "    neck_path = nn_path + str(idx) +\"_neck_network\"\n",
    "\n",
    "    head = torch.load(head_path)\n",
    "    neck = torch.load(neck_path)\n",
    "\n",
    "    head_edit = OrderedDict()\n",
    "    neck_edit = OrderedDict()\n",
    "\n",
    "    # Edit the ordered_dict key names to be torch compatible\n",
    "    for key in head.keys():\n",
    "        head_edit[\"network.\"+key] = head[key]\n",
    "\n",
    "    for key in neck.keys():\n",
    "        neck_edit[\"network.\"+key] = neck[key]\n",
    "\n",
    "    head_nn.load_state_dict(head_edit)\n",
    "    neck_nn.load_state_dict(neck_edit)\n",
    "    \n",
    "    return Victim_NN(head_nn,neck_nn,loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for source in range(1):\n",
    "    \n",
    "    # Bring in the data loader for this client\n",
    "    loader = Dataloader(file_indices,[source*(client_slice),min((source+1)*(client_slice),35)])  \n",
    "    loader.load_training_dataset()\n",
    "    loader.load_testing_dataset()\n",
    "    \n",
    "    victim_source = load_victim(source,loader)\n",
    "    \n",
    "    # Generate adversarial Perturbations\n",
    "    victim_source.i_fgsm(batch_size = batch_size, target= target, eps=eps, alpha=alpha, \n",
    "               iteration=iteration, x_val_min=-1, x_val_max=1, print_info=False)\n",
    "    \n",
    "    # Record relevant tensors\n",
    "    x_orig = victim_source.x_orig\n",
    "    y_orig = victim_source.output_orig\n",
    "    y_true = victim_source.y_orig\n",
    "    x_adv = victim_source.x_adv\n",
    "    y_adv = victim_source.output_adv\n",
    "    \n",
    "    print(\"======== Source\", source, \"========\")\n",
    "    \n",
    "    for dest in range(config['num_clients']):\n",
    "        \n",
    "        print(\"    ==== Dest\", dest, \"====\")\n",
    "        \n",
    "        victim_dest = load_victim(dest,loader)\n",
    "            \n",
    "        # Compute Stats and record\n",
    "        victim_dest.forward_transfer(x_orig,x_adv,y_orig,y_adv,y_true, target, print_info=False)\n",
    "        \n",
    "        orig_acc_transfers[source,dest] = victim_dest.orig_test_acc\n",
    "        orig_similarities[source,dest] = victim_dest.orig_output_sim\n",
    "        orig_target_hit[source,dest] = victim_dest.orig_target_achieve\n",
    "        \n",
    "        adv_acc_transfers[source,dest] = victim_dest.adv_test_acc\n",
    "        adv_similarities[source,dest] = victim_dest.adv_output_sim\n",
    "        adv_target_hit[source,dest] = victim_dest.adv_target_achieve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"orig_acc_transfers\\n\",np.round(orig_acc_transfers,3))\n",
    "print(\"orig_similarities\\n\",np.round(orig_similarities,3))\n",
    "print(\"orig_target_hit\\n\",np.round(orig_target_hit,3))\n",
    "print(\"adv_acc_transfers\\n\",np.round(adv_acc_transfers,3))\n",
    "print(\"adv_similarities\\n\",np.round(adv_similarities,3))\n",
    "print(\"adv_target_hit\\n\",np.round(adv_target_hit,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
