{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instance Based Sweeping\n",
    "\n",
    "TJ Kim <br/>\n",
    "3/8/21\n",
    "\n",
    "Updated <br/>\n",
    "3/8/21\n",
    "\n",
    "#### Objective: \n",
    "Run experiments given new transferability metrics where we sweep across the following parameters: <br/>\n",
    "\n",
    "Inputs:<br/>\n",
    "- Number of Layers\n",
    "- Number of iterations (FGSM)\n",
    "- Confidence Parameter (C&W)\n",
    "\n",
    "Outputs:<br/>\n",
    "- Old Transferability Metrics (Label Based)\n",
    "- New Transferability Metrics (Empirical)\n",
    "\n",
    "Also, print outputs to excel files in a organized fashion (tables).\n",
    "\n",
    "Also, for the transferability metrics, split between successfully fooled and unsuccessfully fooled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/FedAtk\n"
     ]
    }
   ],
   "source": [
    "cd '/home/ubuntu/FedAtk/' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Relevant Libraries and Modules\n",
    "\n",
    "Load the relevant libraries for the federated learning code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transferer\n",
    "from transfer_attacks.Transferer import *\n",
    "from configs.overwrite_config import *\n",
    "\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Organize Experiment Parameters\n",
    "\n",
    "Sort the following:<br/>\n",
    "- Names of the different layers\n",
    "- Save folder for csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make directory in results for this experiment\n",
    "exp_name = '21_3_8 Experiment - Instance Based Sweeping'\n",
    "exp_path = \"results/\" + exp_name\n",
    "if not os.path.isdir(exp_path):\n",
    "    os.mkdir(exp_path)\n",
    "    \n",
    "# FL Architecture\n",
    "client_idx = 0\n",
    "victim_idxs = [0,1,2,3]\n",
    "\n",
    "# Saved Neural Networks to Test on \n",
    "exp_names = [\"exp4_neck2_0_head3\",\n",
    "             \"exp4_neck2_1_head2\",\n",
    "             \"exp4_neck2_2_head1\"]\n",
    "\n",
    "# Parameters to record for excel printing\n",
    "num_clients = 4\n",
    "metrics = ['orig_acc','orig_sim','adv_sim','adv_hit','g_align']\n",
    "ifgsm_iterations = [1,10,20,30]\n",
    "\n",
    "# Save 1 - neck2_head3 network per client metric storage\n",
    "stored_per_client_fgsm = {}\n",
    "stored_per_client_cw = {}\n",
    "stored_per_client_fgsm['num_clients'] = np.arange(num_clients)\n",
    "for i in metrics:\n",
    "    stored_per_client_fgsm[i] = np.zeros(num_clients)\n",
    "\n",
    "# Save 2 - Across all networks\n",
    "stored_per_layer_fgsm = {}\n",
    "stored_per_layer_cw = {}\n",
    "stored_per_layer_fgsm['exp_name'] = exp_names\n",
    "for i in metrics:\n",
    "    stored_per_layer_fgsm[i] = np.zeros(len(exp_names))\n",
    "    \n",
    "# Save 3 - neck2_head3 ifsgm iteration sweep\n",
    "stored_fgsm_iteration = {}\n",
    "stored_fgsm_iteration['iterations'] = ifgsm_iterations\n",
    "for i in metrics:\n",
    "    stored_fgsm_iteration[i] = np.zeros(len(ifgsm_iterations))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading  all_data_12_niid_0_keep_0_train_9.json\n",
      "Loading  all_data_20_niid_0_keep_0_train_9.json\n",
      "Loading  all_data_11_niid_0_keep_0_train_9.json\n",
      "Loading  all_data_18_niid_0_keep_0_train_9.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.8/site-packages/torch/nn/_reduction.py:43: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated model\n",
      "starting experiment 1\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-3638dd5f91fb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m# Log Values per server\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_clients\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mstored_per_client_fgsm\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'orig_acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransferer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0morig_acc_transfers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0mstored_per_client_fgsm\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'orig_sim'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransferer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0morig_similarities\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mstored_per_client_fgsm\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'adv_sim'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransferer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madv_similarities\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "# Experiment 1 - Per Client transfer metrics\n",
    "\n",
    "# Generate NN and Victims\n",
    "transferer = Transferer(filename = exp_names[0])\n",
    "transferer.generate_advNN(client_idx = client_idx)\n",
    "transferer.generate_victims(client_idxs = victim_idxs)\n",
    "print('generated model')\n",
    "\n",
    "# FGSM Attack\n",
    "print('starting experiment 1')\n",
    "transferer.generate_xadv(atk_type = \"ifsgm\")\n",
    "transferer.send_to_victims(victim_idxs, split_flag=True)\n",
    "transferer.check_empirical_metrics(orig_flag = True)\n",
    "\n",
    "# Log Values per server\n",
    "for i in range(num_clients):\n",
    "    stored_per_client_fgsm['orig_acc'][i] = transferer.orig_acc_transfers[i]\n",
    "    stored_per_client_fgsm['orig_sim'][i] = transferer.orig_similarities[i]\n",
    "    stored_per_client_fgsm['adv_sim'][i] = transferer.adv_similarities[i]\n",
    "    stored_per_client_fgsm['adv_hit'][i] = transferer.adv_target_hit[i]\n",
    "    stored_per_client_fgsm['g_align'][i] = transferer.metric_alignment[i]\n",
    "\n",
    "print('finished IFGSM Attack')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(496.0000, device='cuda:0')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transferer.victims[0].adv_target_achieve*500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
