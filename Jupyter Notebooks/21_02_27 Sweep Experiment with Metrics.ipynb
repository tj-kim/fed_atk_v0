{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sweep Experiment with Metrics\n",
    "\n",
    "TJ Kim <br/>\n",
    "2/27/21\n",
    "\n",
    "Updated <br/>\n",
    "2/27/21\n",
    "\n",
    "#### Objective: \n",
    "Run experiments given new transferability metrics where we sweep across the following parameters: <br/>\n",
    "\n",
    "Inputs:<br/>\n",
    "- Number of Layers\n",
    "- Number of iterations (FGSM)\n",
    "- Confidence Parameter (C&W)\n",
    "\n",
    "Outputs:<br/>\n",
    "- Old Transferability Metrics (Label Based)\n",
    "- New Transferability Metrics (Empirical)\n",
    "\n",
    "Also, print outputs to excel files in a organized fashion (tables)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/FedAtk\n"
     ]
    }
   ],
   "source": [
    "cd '/home/ubuntu/FedAtk/' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Relevant Libraries and Modules\n",
    "\n",
    "Load the relevant libraries for the federated learning code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transferer\n",
    "from transfer_attacks.Transferer import *\n",
    "from configs.overwrite_config import *\n",
    "\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Organize Experiment Parameters\n",
    "\n",
    "Sort the following:<br/>\n",
    "- Names of the different layers\n",
    "- Save folder for csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make directory in results for this experiment\n",
    "exp_name = '21_3_2 Experiment 1'\n",
    "exp_path = \"results/\" + exp_name\n",
    "if not os.path.isdir(exp_path):\n",
    "    os.mkdir(exp_path)\n",
    "    \n",
    "# FL Architecture\n",
    "client_idx = 0\n",
    "victim_idxs = [0,1,2,3,4,5,6,7]\n",
    "\n",
    "# Saved Neural Networks to Test on \n",
    "exp_names = [\"exp4_neck2_0_head3\",\n",
    "             \"exp4_neck2_1_head2\",\n",
    "             \"exp4_neck2_2_head1\"]\n",
    "\n",
    "# Parameters to record for excel printing\n",
    "num_clients = 8\n",
    "metrics = ['orig_acc','orig_sim','adv_sim','adv_hit','g_align']\n",
    "ifgsm_iterations = [1,10,20,30]\n",
    "cw_confidences = [0, 5, 10, 20]\n",
    "\n",
    "# Save 1 - neck2_head3 network per client metric storage\n",
    "stored_per_client_fgsm = {}\n",
    "stored_per_client_cw = {}\n",
    "stored_per_client_fgsm['num_clients'] = np.arange(num_clients)\n",
    "stored_per_client_cw['num_clients'] = np.arange(num_clients)\n",
    "for i in metrics:\n",
    "    stored_per_client_fgsm[i] = np.zeros(num_clients)\n",
    "    stored_per_client_cw[i] = np.zeros(num_clients)\n",
    "\n",
    "# Save 2 - Across all networks\n",
    "stored_per_layer_fgsm = {}\n",
    "stored_per_layer_cw = {}\n",
    "stored_per_layer_fgsm['exp_name'] = exp_names\n",
    "stored_per_layer_cw['exp_name'] = exp_names\n",
    "for i in metrics:\n",
    "    stored_per_layer_fgsm[i] = np.zeros(len(exp_names))\n",
    "    stored_per_layer_cw[i] = np.zeros(len(exp_names))\n",
    "    \n",
    "# Save 3 - neck2_head3 ifsgm iteration sweep\n",
    "stored_fgsm_iteration = {}\n",
    "stored_fgsm_iteration['iterations'] = ifgsm_iterations\n",
    "for i in metrics:\n",
    "    stored_fgsm_iteration[i] = np.zeros(len(ifgsm_iterations))\n",
    "\n",
    "# Save 4 - neck2_head3 CW confidence sweep\n",
    "stored_cw_confidence = {}\n",
    "stored_cw_confidence['confidence'] = cw_confidences\n",
    "for i in metrics:\n",
    "    stored_cw_confidence[i] = np.zeros(len(cw_confidences))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Experiment 2 - Per Layer Transfer Metric\n",
    "for l in range(len(exp_names)):\n",
    "\n",
    "    # Overwrite config\n",
    "    overwrite_config(exp_names[l])\n",
    "    \n",
    "    # Generate NN and Victims\n",
    "    transferer = Transferer(filename = exp_names[l])\n",
    "    transferer.generate_advNN(client_idx = client_idx)\n",
    "    # transferer.generate_victims(client_idxs = victim_idxs)\n",
    "    print('generated model', l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the experiments\n",
    "\n",
    "Load different experiments and fill in the tables.\n",
    "\n",
    "First run first simulation regarding checking different servers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "Loading  all_data_12_niid_0_keep_0_train_9.json\n",
      "Loading  all_data_20_niid_0_keep_0_train_9.json\n",
      "Loading  all_data_11_niid_0_keep_0_train_9.json\n",
      "Loading  all_data_18_niid_0_keep_0_train_9.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.8/site-packages/torch/nn/_reduction.py:43: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load_FLNN exppath: federated_training/Results/federated_system/exp4_neck2_0_head3/exp4_neck2_0_head3_\n",
      "load_FLNN exppath: federated_training/Results/federated_system/exp4_neck2_0_head3/exp4_neck2_0_head3_\n",
      "load_FLNN exppath: federated_training/Results/federated_system/exp4_neck2_0_head3/exp4_neck2_0_head3_\n",
      "load_FLNN exppath: federated_training/Results/federated_system/exp4_neck2_0_head3/exp4_neck2_0_head3_\n",
      "load_FLNN exppath: federated_training/Results/federated_system/exp4_neck2_0_head3/exp4_neck2_0_head3_\n",
      "load_FLNN exppath: federated_training/Results/federated_system/exp4_neck2_0_head3/exp4_neck2_0_head3_\n",
      "load_FLNN exppath: federated_training/Results/federated_system/exp4_neck2_0_head3/exp4_neck2_0_head3_\n",
      "load_FLNN exppath: federated_training/Results/federated_system/exp4_neck2_0_head3/exp4_neck2_0_head3_\n",
      "load_FLNN exppath: federated_training/Results/federated_system/exp4_neck2_0_head3/exp4_neck2_0_head3_\n",
      "generated model\n",
      "starting experiment 1\n",
      "finished IFGSM Attack\n",
      "finished CW Attack\n",
      "starting experiment 3\n",
      "finished fgsm iter sweep 0\n",
      "finished fgsm iter sweep 1\n",
      "finished fgsm iter sweep 2\n",
      "finished fgsm iter sweep 3\n",
      "starting experiment 4\n",
      "finished cw confidence sweep 0\n",
      "finished cw confidence sweep 1\n",
      "finished cw confidence sweep 2\n",
      "finished cw confidence sweep 3\n"
     ]
    }
   ],
   "source": [
    "# Experiment 1 - Per Client transfer metrics\n",
    "\n",
    "# Generate NN and Victims\n",
    "transferer = Transferer(filename = exp_names[0])\n",
    "transferer.generate_advNN(client_idx = client_idx)\n",
    "transferer.generate_victims(client_idxs = victim_idxs)\n",
    "print('generated model')\n",
    "\n",
    "# FGSM Attack\n",
    "print('starting experiment 1')\n",
    "transferer.generate_xadv(atk_type = \"ifsgm\")\n",
    "transferer.send_to_victims(victim_idxs)\n",
    "transferer.check_empirical_metrics(orig_flag = True)\n",
    "\n",
    "# Log Values per server\n",
    "for i in range(num_clients):\n",
    "    stored_per_client_fgsm['orig_acc'][i] = transferer.orig_acc_transfers[i]\n",
    "    stored_per_client_fgsm['orig_sim'][i] = transferer.orig_similarities[i]\n",
    "    stored_per_client_fgsm['adv_sim'][i] = transferer.adv_similarities[i]\n",
    "    stored_per_client_fgsm['adv_hit'][i] = transferer.adv_target_hit[i]\n",
    "    stored_per_client_fgsm['g_align'][i] = transferer.metric_alignment[i]\n",
    "\n",
    "print('finished IFGSM Attack')\n",
    "\n",
    "# CW Attack\n",
    "transferer.generate_xadv(atk_type = \"cw\")\n",
    "transferer.send_to_victims(victim_idxs)\n",
    "transferer.check_empirical_metrics(orig_flag = True)\n",
    "\n",
    "# Log Values per server\n",
    "for i in range(num_clients):\n",
    "    stored_per_client_cw['orig_acc'][i] = transferer.orig_acc_transfers[i]\n",
    "    stored_per_client_cw['orig_sim'][i] = transferer.orig_similarities[i]\n",
    "    stored_per_client_cw['adv_sim'][i] = transferer.adv_similarities[i]\n",
    "    stored_per_client_cw['adv_hit'][i] = transferer.adv_target_hit[i]\n",
    "    stored_per_client_cw['g_align'][i] = transferer.metric_alignment[i]\n",
    "\n",
    "print('finished CW Attack')\n",
    "\n",
    "\n",
    "# Experiment 3 - FGSM Iteration sweep\n",
    "print(\"starting experiment 3\")\n",
    "for it in range(len(ifgsm_iterations)):\n",
    "    transferer.ifsgm_params.set_params(iteration = ifgsm_iterations[it])\n",
    "    transferer.generate_xadv(atk_type = \"ifsgm\")\n",
    "    transferer.send_to_victims(victim_idxs)\n",
    "    transferer.check_empirical_metrics(orig_flag = True)\n",
    "    \n",
    "    stored_fgsm_iteration['orig_acc'][it] = sum(transferer.orig_acc_transfers.values()) / len(transferer.orig_acc_transfers) \n",
    "    stored_fgsm_iteration['orig_sim'][it] = sum(transferer.orig_similarities.values())/ len(transferer.orig_similarities)\n",
    "    stored_fgsm_iteration['adv_sim'][it] = sum(transferer.adv_similarities.values())/ len(transferer.adv_similarities)\n",
    "    stored_fgsm_iteration['adv_hit'][it] = sum(transferer.adv_target_hit.values())/len(transferer.adv_target_hit)\n",
    "    stored_fgsm_iteration['g_align'][it] = sum(transferer.metric_alignment.values())/len(transferer.metric_alignment)\n",
    "    \n",
    "    print('finished fgsm iter sweep', it)\n",
    "\n",
    "\n",
    "# Experiment 4 - CW Confidence Sweep\n",
    "print(\"starting experiment 4\")\n",
    "for c in range(len(cw_confidences)):\n",
    "    transferer.cw_params.set_params(confidence = cw_confidences[c])\n",
    "    transferer.generate_xadv(atk_type = \"cw\")\n",
    "    transferer.send_to_victims(victim_idxs)\n",
    "    transferer.check_empirical_metrics(orig_flag = True)\n",
    "    \n",
    "    stored_cw_confidence['orig_acc'][c] = sum(transferer.orig_acc_transfers.values()) / len(transferer.orig_acc_transfers) \n",
    "    stored_cw_confidence['orig_sim'][c] = sum(transferer.orig_similarities.values())/ len(transferer.orig_similarities)\n",
    "    stored_cw_confidence['adv_sim'][c] = sum(transferer.adv_similarities.values())/ len(transferer.adv_similarities)\n",
    "    stored_cw_confidence['adv_hit'][c] = sum(transferer.adv_target_hit.values())/len(transferer.adv_target_hit)\n",
    "    stored_cw_confidence['g_align'][c] = sum(transferer.metric_alignment.values())/len(transferer.metric_alignment)\n",
    "    \n",
    "    print('finished cw confidence sweep', c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2nd Simulation regarding same metrics across different layer shared between servers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "Loading  all_data_12_niid_0_keep_0_train_9.json\n",
      "Loading  all_data_20_niid_0_keep_0_train_9.json\n",
      "Loading  all_data_11_niid_0_keep_0_train_9.json\n",
      "Loading  all_data_18_niid_0_keep_0_train_9.json\n",
      "generated model 0\n",
      "finished IFGSM Attack 0\n",
      "finished CW Attack 0\n",
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "Loading  all_data_12_niid_0_keep_0_train_9.json\n",
      "Loading  all_data_20_niid_0_keep_0_train_9.json\n",
      "Loading  all_data_11_niid_0_keep_0_train_9.json\n",
      "Loading  all_data_18_niid_0_keep_0_train_9.json\n",
      "generated model 1\n",
      "finished IFGSM Attack 1\n",
      "finished CW Attack 1\n",
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "Loading  all_data_12_niid_0_keep_0_train_9.json\n",
      "Loading  all_data_20_niid_0_keep_0_train_9.json\n",
      "Loading  all_data_11_niid_0_keep_0_train_9.json\n",
      "Loading  all_data_18_niid_0_keep_0_train_9.json\n",
      "generated model 2\n",
      "finished IFGSM Attack 2\n",
      "finished CW Attack 2\n"
     ]
    }
   ],
   "source": [
    "# Experiment 2 - Per Layer Transfer Metric\n",
    "print(\"Running Exp 2\")\n",
    "\n",
    "for l in range(len(exp_names)):\n",
    "    # Generate NN and Victims\n",
    "    transferer = Transferer(filename = exp_names[l])\n",
    "    transferer.generate_advNN(client_idx = client_idx)\n",
    "    transferer.generate_victims(client_idxs = victim_idxs)\n",
    "    print('generated model', l)\n",
    "\n",
    "    # FGSM Attack\n",
    "    transferer.generate_xadv(atk_type = \"ifsgm\")\n",
    "    transferer.send_to_victims(victim_idxs)\n",
    "    transferer.check_empirical_metrics(orig_flag = True)\n",
    "\n",
    "    # Log Values per layer\n",
    "    stored_per_layer_fgsm['orig_acc'][l] = sum(transferer.orig_acc_transfers.values()) / len(transferer.orig_acc_transfers) \n",
    "    stored_per_layer_fgsm['orig_sim'][l] = sum(transferer.orig_similarities.values())/ len(transferer.orig_similarities)\n",
    "    stored_per_layer_fgsm['adv_sim'][l] = sum(transferer.adv_similarities.values())/ len(transferer.adv_similarities)\n",
    "    stored_per_layer_fgsm['adv_hit'][l] = sum(transferer.adv_target_hit.values())/len(transferer.adv_target_hit)\n",
    "    stored_per_layer_fgsm['g_align'][l] = sum(transferer.metric_alignment.values())/len(transferer.metric_alignment)\n",
    "\n",
    "    print('finished IFGSM Attack', l)\n",
    "\n",
    "    # CW Attack\n",
    "    transferer.generate_xadv(atk_type = \"cw\")\n",
    "    transferer.send_to_victims(victim_idxs)\n",
    "    transferer.check_empirical_metrics(orig_flag = True)\n",
    "\n",
    "    # Log Values per server\n",
    "    stored_per_layer_cw['orig_acc'][l] = sum(transferer.orig_acc_transfers.values()) / len(transferer.orig_acc_transfers) \n",
    "    stored_per_layer_cw['orig_sim'][l] = sum(transferer.orig_similarities.values())/ len(transferer.orig_similarities)\n",
    "    stored_per_layer_cw['adv_sim'][l] = sum(transferer.adv_similarities.values())/ len(transferer.adv_similarities)\n",
    "    stored_per_layer_cw['adv_hit'][l] = sum(transferer.adv_target_hit.values())/len(transferer.adv_target_hit)\n",
    "    stored_per_layer_cw['g_align'][l] = sum(transferer.metric_alignment.values())/len(transferer.metric_alignment)\n",
    "\n",
    "    print('finished CW Attack', l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write results to Excel file\n",
    "\n",
    "One excel file for each dictionary (6 in total)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save 1 - neck2_head3 network per client metric storage\n",
    "df1_1 = pd.DataFrame(data=stored_per_client_fgsm).T\n",
    "df1_1.to_excel(exp_path + '/'+'s1_1_per_client_fgsm.xlsx',header=False)\n",
    "\n",
    "df1_2 =  pd.DataFrame(data=stored_per_client_cw).T\n",
    "df1_2.to_excel(exp_path + '/'+'s1_2_per_client_cw.xlsx',header=False)\n",
    "\n",
    "# Save 3 - neck2_head3 ifsgm iteration sweep\n",
    "df3 = pd.DataFrame(data=stored_fgsm_iteration).T\n",
    "df3.to_excel(exp_path + '/' + 's3_fgsm_iterations.xlsx',header=False)\n",
    "\n",
    "# Save 4 - neck2_head3 CW confidence sweep\n",
    "df4 = pd.DataFrame(data=stored_cw_confidence).T\n",
    "df4.to_excel(exp_path + '/' + 's4_cw_confidence.xlsx', header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save 2 - Across all networks\n",
    "df2_1 = pd.DataFrame(data=stored_per_layer_fgsm).T\n",
    "df2_1.to_excel(exp_path + '/'+'s2_1_per_layer_fgsm.xlsx',header=False)\n",
    "\n",
    "df2_2 = pd.DataFrame(data=stored_per_layer_cw).T\n",
    "df2_2.to_excel(exp_path + '/'+'s2_2_per_layer_cw.xlsx',header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
