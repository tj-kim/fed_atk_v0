{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FGSM Sweep 1\n",
    "\n",
    "TJ Kim <br/>\n",
    "1/16/21\n",
    "\n",
    "#### Objective: \n",
    "Run FGSM attack on different number of head layers in federated learning and observe performance,\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/FedAtk\n"
     ]
    }
   ],
   "source": [
    "cd '/home/ubuntu/FedAtk/' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Relevant Libraries and Modules\n",
    "\n",
    "Load the relevant libraries for the federated learning code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import yaml\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import csv\n",
    "import os\n",
    "import pickle\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import multiprocessing as mp\n",
    "import queue\n",
    "\n",
    "# Extra not from py file\n",
    "from collections import OrderedDict \n",
    "import itertools\n",
    "\n",
    "from __future__ import print_function\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Import Custom Made Victim\n",
    "from transfer_attacks.Personalized_NN import *\n",
    "\n",
    "# Federated Learning Module        \n",
    "from federated_training.femnist_dataloader import Dataloader\n",
    "from federated_training.cnn_head import CNN_Head\n",
    "from federated_training.cnn_neck import CNN_Neck\n",
    "from federated_training.cnn_server import Server\n",
    "from federated_training.cnn_client import Client\n",
    "from federated_training.data_manager import DataManager\n",
    "from federated_training.utils import cuda, where\n",
    "\n",
    "from federated_training.utilities import freeze_layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transfer Attack Sweeping Different Configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IFSGM_Params():\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        # Attack Params\n",
    "        self.batch_size = 10\n",
    "        self.eps = 0.1\n",
    "        self.alpha = 0.01\n",
    "        self.iteration = 100\n",
    "        self.target = 20\n",
    "        self.x_val_min = 0\n",
    "        self.x_val_max = 1\n",
    "        \n",
    "    def set_params(self, batch_size=None, eps=None, alpha=None, iteration = None,\n",
    "                   target = None, x_val_min = None, x_val_max = None):\n",
    "        \n",
    "        if batch_size is not None:\n",
    "            self.batch_size = batch_size\n",
    "            \n",
    "        if eps is not None:\n",
    "            self.eps = eps\n",
    "            \n",
    "        if alpha is not None:\n",
    "            self.alpha = alpha\n",
    "            \n",
    "        if iteration is not None:\n",
    "            self.iteration = iteration\n",
    "            \n",
    "        if target is not None:\n",
    "            self.target = target\n",
    "            \n",
    "        if x_val_min is not None:\n",
    "            self.x_val_min = x_val_min\n",
    "            \n",
    "        if x_val_max is not None:\n",
    "            self.x_val_max = x_val_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transferer(): \n",
    "    \"\"\"\n",
    "    - Collect all the FL NN \n",
    "    - Implement transfer attack sweep\n",
    "    - Hold all the metrics of interest\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, filename:str, config_name = None):\n",
    "        \n",
    "        # TO IMPLEMENT - Overwrite current file with config_name\n",
    "        with open(r'configs/config.yaml') as file:\n",
    "            self.config = yaml.load(file, Loader=yaml.FullLoader)\n",
    "            \n",
    "        self.file = filename\n",
    "        \n",
    "        # Matrix to Record Performance (Old Metrics)\n",
    "        self.orig_acc_transfers = {}\n",
    "        self.orig_similarities = {}\n",
    "        self.orig_target_hit = {}\n",
    "        self.adv_acc_transfers = {}\n",
    "        self.adv_similarities = {}\n",
    "        self.adv_target_hit = {}\n",
    "        \n",
    "        # Matrix to Record Performance (New Metrics - theoretical)\n",
    "        \n",
    "        # Attack Params\n",
    "        self.ifsgm_params = IFSGM_Params()\n",
    "        # self.cw_params = IFSGM_Params()\n",
    "        \n",
    "        # Other Params\n",
    "        self.advNN_idx = None # int\n",
    "        self.advNN = None # pytorch nn\n",
    "        self.victim_idxs = None # List of ints\n",
    "        self.victims = None # dict of pytorch nn\n",
    "        \n",
    "        # Recorded Data Points\n",
    "        self.x_orig = None\n",
    "        self.y_orig = None\n",
    "        self.y_true = None\n",
    "        self.x_adv = None\n",
    "        self.y_adv = None\n",
    "        \n",
    "    def generate_advNN(self, client_idx):\n",
    "        \"\"\"\n",
    "        Select specific client to load neural network to \n",
    "        Load the data for that client\n",
    "        Lod the weights for that client\n",
    "        This is the client that will generate perturbations\n",
    "        \"\"\"\n",
    "        \n",
    "        # Import Data Loader for this FL set\n",
    "        file_indices = [i for i in range(self.config['num_sets'])]\n",
    "        client_slice = len(file_indices)//self.config['num_clients']\n",
    "        \n",
    "        # Import the loader for this dataset only\n",
    "        self.loader = Dataloader(file_indices,[client_idx*(client_slice),min((client_idx+1)*(client_slice),35)])  \n",
    "        self.loader.load_training_dataset()\n",
    "        self.loader.load_testing_dataset()\n",
    "        \n",
    "        self.advNN_idx = client_idx\n",
    "        self.advNN = load_FLNN(idx=client_idx, direc=self.file, loader=self.loader)\n",
    "        \n",
    "        return\n",
    "    \n",
    "    def generate_xadv(self):\n",
    "        \"\"\"\n",
    "        Generate perturbed images\n",
    "        \"\"\"\n",
    "        \n",
    "        self.advNN.i_fgsm(self.ifsgm_params)\n",
    "        \n",
    "        # Record relevant tensors\n",
    "        self.x_orig = self.advNN.x_orig\n",
    "        self.y_orig = self.advNN.output_orig\n",
    "        self.y_true = self.advNN.y_orig\n",
    "        self.x_adv = self.advNN.x_adv\n",
    "        self.y_adv = self.advNN.output_adv\n",
    "    \n",
    "    def generate_victims(self, client_idxs):\n",
    "        \"\"\"\n",
    "        Load the pre-trained other clients in the system\n",
    "        \"\"\"\n",
    "        \n",
    "        self.victim_idxs = client_idxs\n",
    "        self.victims = {}\n",
    "    \n",
    "        for i in self.victim_idxs:\n",
    "            self.victims[i] = load_FLNN(idx=i, direc=self.file, loader=None)\n",
    "    \n",
    "    def send_to_victims(self, client_idxs):\n",
    "        \"\"\"\n",
    "        Send pre-generated adversarial perturbations \n",
    "        client_idxs - list of indices of clients we want to attack (just victims)\n",
    "        \n",
    "        Then record the attack success stats accordingly\n",
    "        \"\"\"\n",
    "        \n",
    "        for i in client_idxs:\n",
    "            self.victims[i].forward_transfer(self.x_orig,self.x_adv,\n",
    "                                         self.y_orig,self.y_adv,\n",
    "                                         self.y_true, self.ifsgm_params.target, \n",
    "                                         print_info=False)\n",
    "            \n",
    "            # Record Performance\n",
    "            self.orig_acc_transfers[i] = self.victims[i].orig_test_acc\n",
    "            self.orig_similarities[i] = self.victims[i].orig_output_sim\n",
    "            self.orig_target_hit[i] = self.victims[i].orig_target_achieve\n",
    "\n",
    "            self.adv_acc_transfers[i] = self.victims[i].adv_test_acc\n",
    "            self.adv_similarities[i] = self.victims[i].adv_output_sim\n",
    "            self.adv_target_hit[i] = self.victims[i].adv_target_achieve\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading  all_data_12_niid_0_keep_0_train_9.json\n",
      "Loading  all_data_20_niid_0_keep_0_train_9.json\n",
      "Loading  all_data_11_niid_0_keep_0_train_9.json\n",
      "Loading  all_data_18_niid_0_keep_0_train_9.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.8/site-packages/torch/nn/_reduction.py:43: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    }
   ],
   "source": [
    "client_idx = 0\n",
    "victim_idxs = [0,1,2,3]\n",
    "\n",
    "transferer = Transferer(filename = 'exp2_neck2_head3')\n",
    "transferer.generate_advNN(client_idx = client_idx)\n",
    "transferer.generate_victims(client_idxs = victim_idxs)\n",
    "transferer.ifsgm_params = IFSGM_Params()\n",
    "transferer.generate_xadv()\n",
    "transferer.send_to_victims(victim_idxs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "orig_acc_transfers\n",
      " tensor(0.9000, device='cuda:0')\n",
      "orig_similarities\n",
      " tensor(0.9000, device='cuda:0')\n",
      "orig_target_hit\n",
      " tensor(0., device='cuda:0')\n",
      "adv_acc_transfers\n",
      " tensor(0., device='cuda:0')\n",
      "adv_similarities\n",
      " tensor(0.9000, device='cuda:0')\n",
      "adv_target_hit\n",
      " tensor(0.9000, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "j = 3\n",
    "\n",
    "print(\"orig_acc_transfers\\n\",transferer.orig_acc_transfers[j])\n",
    "print(\"orig_similarities\\n\",transferer.orig_similarities[j])\n",
    "print(\"orig_target_hit\\n\",transferer.orig_target_hit[j])\n",
    "print(\"adv_acc_transfers\\n\",transferer.adv_acc_transfers[j])\n",
    "print(\"adv_similarities\\n\",transferer.adv_similarities[j])\n",
    "print(\"adv_target_hit\\n\",transferer.adv_target_hit[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([40, 24,  3, 18,  7, 30,  5, 24,  0, 49], device='cuda:0')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transferer.y_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([40, 24,  3, 18,  7, 30,  5, 24,  0, 49], device='cuda:0')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.argmax(transferer.advNN(transferer.x_orig),dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([20, 20, 20, 20, 20, 20, 20, 20, 20, 20], device='cuda:0')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.argmax(transferer.advNN(transferer.x_adv),dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([20, 20, 20, 20, 20, 20, 20, 20, 20, 20], device='cuda:0')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.argmax(transferer.victims[0](transferer.x_adv),dim = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
